{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to the Scava documentation\n\n\nIn DOCS",
            "title": "Home"
        },
        {
            "location": "/#welcome-to-the-scava-documentation",
            "text": "In DOCS",
            "title": "Welcome to the Scava documentation"
        },
        {
            "location": "/admin/API-Gateway-Configuration/",
            "text": "API Gateway configuration\n\n\nWhen to use this guideline ?\n\n\nThis guideline presents how to configure the CROSSMINER Gateway in order to integrate a new remote REST API.\n\n\nContext\n\n\nThe CROSSMINER Gateway can be configured by the intermediary of an external property file (application.properties) to place in the execution directory of the CROSSMINER Gateway component. This file allow to configure the routing of requests send to the gateway an some security parameters.\n\n\nRouting : Service Configuration\n\n\nTo reference a new remote REST API in the gateway, you have to add  2 new properties in the application.properties configuration file : the relative path of services  which will be integrated to this route and the redirection URL.All requests sent to the gateway which start by this relatice path will be redirected to the output url after the authentication process.\n\n\nExamples :\n\n api gateway url = http://85.36.10.13:8080\n\n path = /administration/*\n\n\n url = http://85.36.10.12:8082/administration\n\n\nThe request http://85.36.10.13:8080/administration/project/create will be redirected to http://85.36.10.12:8082/administration/project/create\n\n\n\n\nid : \nzuul.routes.**servicename**.path\ndefault :\n NA\n\n\nRelative path of the incoming service which will be redirected. Example : /test1/**\n\n\n\n\n\n\n\nid : \nzuul.routes.**servicename**.url\ndefault :\n NA\n\n\nRedirection URL of the route. Example : http://127.0.0.1:8082/test1\n\n\n\n\n\nConfiguration file example\n\n\n# Rooting Configuration : Test1 Service\nzuul.routes.test1.path=/test1/**\nzuul.routes.test1.url=http://127.0.0.1:8082/test1\n\n# Rooting Configuration : Test2 Service\nzuul.routes.test2.path=/test2/**\nzuul.routes.test2.url=http://127.0.0.1:8083/test2\n\n\n\n\nComments\n\n\nMore information about API Gateway configuration : [[API Gateway Component]]",
            "title": "API Gateway Configuration"
        },
        {
            "location": "/admin/API-Gateway-Configuration/#api-gateway-configuration",
            "text": "",
            "title": "API Gateway configuration"
        },
        {
            "location": "/admin/API-Gateway-Configuration/#when-to-use-this-guideline",
            "text": "This guideline presents how to configure the CROSSMINER Gateway in order to integrate a new remote REST API.",
            "title": "When to use this guideline ?"
        },
        {
            "location": "/admin/API-Gateway-Configuration/#context",
            "text": "The CROSSMINER Gateway can be configured by the intermediary of an external property file (application.properties) to place in the execution directory of the CROSSMINER Gateway component. This file allow to configure the routing of requests send to the gateway an some security parameters.",
            "title": "Context"
        },
        {
            "location": "/admin/API-Gateway-Configuration/#routing-service-configuration",
            "text": "To reference a new remote REST API in the gateway, you have to add  2 new properties in the application.properties configuration file : the relative path of services  which will be integrated to this route and the redirection URL.All requests sent to the gateway which start by this relatice path will be redirected to the output url after the authentication process.  Examples :  api gateway url = http://85.36.10.13:8080  path = /administration/*   url = http://85.36.10.12:8082/administration  The request http://85.36.10.13:8080/administration/project/create will be redirected to http://85.36.10.12:8082/administration/project/create   id :  zuul.routes.**servicename**.path default :  NA  Relative path of the incoming service which will be redirected. Example : /test1/**    id :  zuul.routes.**servicename**.url default :  NA  Redirection URL of the route. Example : http://127.0.0.1:8082/test1",
            "title": "Routing : Service Configuration"
        },
        {
            "location": "/admin/API-Gateway-Configuration/#configuration-file-example",
            "text": "# Rooting Configuration : Test1 Service\nzuul.routes.test1.path=/test1/**\nzuul.routes.test1.url=http://127.0.0.1:8082/test1\n\n# Rooting Configuration : Test2 Service\nzuul.routes.test2.path=/test2/**\nzuul.routes.test2.url=http://127.0.0.1:8083/test2",
            "title": "Configuration file example"
        },
        {
            "location": "/admin/API-Gateway-Configuration/#comments",
            "text": "More information about API Gateway configuration : [[API Gateway Component]]",
            "title": "Comments"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/",
            "text": "When to use ?\n\n\nThis guideline present how to the CROSSMINER Platform can access to his data stored in a MongoDb data base. The guideline describe how to create a connection to the MongoDb database and how to perform CRUD operation on platform datas.\n\n\nContext\n\n\nThe CROSSMINER platform use a MongoDb data base to store his data. We go through \nPONGO\n, a template based \nJava POJO generator\n to access \nMongoDB\n database. With Pongo we can define the data model which generates strongly-typed Java classes.\n\n\nIn this guideligne, we will present  : \n\n The access to MongoDb Document on from aneclipse plugin integrate to the CROSSMINER platform.\n\n The access to MongoDb Document on from an external Java application.\n* How to preform basic CRUD operation with a PONGO Java data model.\n\n\nWe consider that the PONGO Java data model already exist. If it's not the case , please refer the fooling guideline to create the data model : https://github.com/crossminer/crossminer/wiki/Extend-MongoDB-Data-Model\n\n\nYou want to access to MongoDB Document from an Eclipse Plugin ?\n\n\n1. Add a dependency to the Java Data Model\n\n\n\n\nEdit the plugin.xml file of your plugin.\n\n\nIn Dependency section, add a dependency to  the plugin which contained the data model you went to access.\n\n\nTo \norg.ossmeter.repository.model\n to access data related to project administration , metric execution process and authentification system.\n\n\nTo \norg.ossmeter.repository.model.'project delta manager'\n to access  configuration informations related to source codes managemeny tools.\n\n\nTo  \nspecific metric provider plugins\n  to access data related to a specific metric provider implementation contains his once data model.\n\n\n... others plugin which contained the data model\n\n\nIn Dependency section, add a dependency to \ncom.googlecode.pongo.runtime\n plugin\n\n\n\n\n\n\n2. Initiate a Connection to the MongoDb\n\n\nIn context of the CROSSMINER platform, a Configuration service allow you to initiate a connection whit the mongoDb data base.\n\n\n\n\nIn Dependency section of plugin.xml file , add a dependency to the \norg.ossmeter.platform\n plugin.\n\n\nYou can now create a new connection to the database using the Configuration service.\n\n\n\n\nMongo mongo = Configuration.getInstance().getMongoConnection(); \n\n\n\n\nYou want to access to MongoDB Document on from an External Java Application ?\n\n\n1. Add a dependency to the Java Data Model\n\n\n\n\nAdd to your java project a dependency to the jar which contained  the data model you went to access. You will have to deliver this jar with your application.\n\n\n\n\n\n\n\n\nAdd o your java project a dependency to the \npongo.jar\n jar file which can be download at this url : https://github.com/kolovos/pongo/releases\n\n\n\n\n2. Initiate a Connection to MongoDb\n\n\n// Define ServerAddress of the MongoDb database\nList<ServerAddress> mongoHostAddresses = new ArrayList<>();\nmongoHostAddresses.add(new ServerAddress(s[0], Integer.valueOf(s[1])));\n\n// Create Connection\nMongo mongo = new Mongo(mongoHostAddresses);\n\n\n\n\nOnce the connection to MongoDb has been created, you have to make the link  between the PONGO Java model and the database. On a MongoDb Server, data are organize by database. You need to know the name of the database to link the Java model with the MongoDb document.\n\n\nDB db =  mongo.getDB(\"databasename\");\n\n// Initiate the Project Java model\nProjectRepository = new ProjectRepository(db);\n\n\n\n\nBasic CRUD with a PONGO Java data model\n\n\n1. CREATE\n\n\n// Connect the Data model to the database\nDB db =  mongo.getDB(\"databasename\");\nMetricProvider metricprovider = new MetricProvider(db);\n\n// Used accessors to intialise the object\nmetricprovider.setName(\"Metric1\").\n......\n\n// Create the Document\nmetricprovider.sync(true);\n\n\n\n\n2. READ\n\n\n// Connect the Data model to the database\nDB db =  mongo.getDB(\"databasename\");\nMetricProvider metricprovider = new MetricProvider(db);\n\n// Used accessors to access object properties\nmetricprovider.getname();\n......\n\n\n\n\n3. UPDATE\n\n\n// Connect the Data model to the database\nDB db =  mongo.getDB(\"databasename\");\nMetricProvider metricprovider = new MetricProvider(db);\n\n// Used accessors to intialise the object\nmetricprovider.setName(\"Metric1\").\n......\n\n// Create the Document\nmetricprovider.sync(true);\n\n\n\n\n4. DELETE\n\n\nMongo mongo = new Mongo();\nmongo.dropDatabase(\"databasename\");\n\n\nComment\n\n\nThis wiki has dealt with the access of MongoDB database using PONGO. To continue learning how to modify and make a new model with Pongo, we have another page here \nlink\n .",
            "title": "Access to MongoDB database using PONGO"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#when-to-use",
            "text": "This guideline present how to the CROSSMINER Platform can access to his data stored in a MongoDb data base. The guideline describe how to create a connection to the MongoDb database and how to perform CRUD operation on platform datas.",
            "title": "When to use ?"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#context",
            "text": "The CROSSMINER platform use a MongoDb data base to store his data. We go through  PONGO , a template based  Java POJO generator  to access  MongoDB  database. With Pongo we can define the data model which generates strongly-typed Java classes.  In this guideligne, we will present  :   The access to MongoDb Document on from aneclipse plugin integrate to the CROSSMINER platform.  The access to MongoDb Document on from an external Java application.\n* How to preform basic CRUD operation with a PONGO Java data model.  We consider that the PONGO Java data model already exist. If it's not the case , please refer the fooling guideline to create the data model : https://github.com/crossminer/crossminer/wiki/Extend-MongoDB-Data-Model",
            "title": "Context"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#you-want-to-access-to-mongodb-document-from-an-eclipse-plugin",
            "text": "",
            "title": "You want to access to MongoDB Document from an Eclipse Plugin ?"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#1-add-a-dependency-to-the-java-data-model",
            "text": "Edit the plugin.xml file of your plugin.  In Dependency section, add a dependency to  the plugin which contained the data model you went to access.  To  org.ossmeter.repository.model  to access data related to project administration , metric execution process and authentification system.  To  org.ossmeter.repository.model.'project delta manager'  to access  configuration informations related to source codes managemeny tools.  To   specific metric provider plugins   to access data related to a specific metric provider implementation contains his once data model.  ... others plugin which contained the data model  In Dependency section, add a dependency to  com.googlecode.pongo.runtime  plugin",
            "title": "1. Add a dependency to the Java Data Model"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#2-initiate-a-connection-to-the-mongodb",
            "text": "In context of the CROSSMINER platform, a Configuration service allow you to initiate a connection whit the mongoDb data base.   In Dependency section of plugin.xml file , add a dependency to the  org.ossmeter.platform  plugin.  You can now create a new connection to the database using the Configuration service.   Mongo mongo = Configuration.getInstance().getMongoConnection();",
            "title": "2. Initiate a Connection to the MongoDb"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#you-want-to-access-to-mongodb-document-on-from-an-external-java-application",
            "text": "",
            "title": "You want to access to MongoDB Document on from an External Java Application ?"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#1-add-a-dependency-to-the-java-data-model_1",
            "text": "Add to your java project a dependency to the jar which contained  the data model you went to access. You will have to deliver this jar with your application.     Add o your java project a dependency to the  pongo.jar  jar file which can be download at this url : https://github.com/kolovos/pongo/releases",
            "title": "1. Add a dependency to the Java Data Model"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#2-initiate-a-connection-to-mongodb",
            "text": "// Define ServerAddress of the MongoDb database\nList<ServerAddress> mongoHostAddresses = new ArrayList<>();\nmongoHostAddresses.add(new ServerAddress(s[0], Integer.valueOf(s[1])));\n\n// Create Connection\nMongo mongo = new Mongo(mongoHostAddresses);  Once the connection to MongoDb has been created, you have to make the link  between the PONGO Java model and the database. On a MongoDb Server, data are organize by database. You need to know the name of the database to link the Java model with the MongoDb document.  DB db =  mongo.getDB(\"databasename\");\n\n// Initiate the Project Java model\nProjectRepository = new ProjectRepository(db);",
            "title": "2. Initiate a Connection to MongoDb"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#basic-crud-with-a-pongo-java-data-model",
            "text": "",
            "title": "Basic CRUD with a PONGO Java data model"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#1-create",
            "text": "// Connect the Data model to the database\nDB db =  mongo.getDB(\"databasename\");\nMetricProvider metricprovider = new MetricProvider(db);\n\n// Used accessors to intialise the object\nmetricprovider.setName(\"Metric1\").\n......\n\n// Create the Document\nmetricprovider.sync(true);",
            "title": "1. CREATE"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#2-read",
            "text": "// Connect the Data model to the database\nDB db =  mongo.getDB(\"databasename\");\nMetricProvider metricprovider = new MetricProvider(db);\n\n// Used accessors to access object properties\nmetricprovider.getname();\n......",
            "title": "2. READ"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#3-update",
            "text": "// Connect the Data model to the database\nDB db =  mongo.getDB(\"databasename\");\nMetricProvider metricprovider = new MetricProvider(db);\n\n// Used accessors to intialise the object\nmetricprovider.setName(\"Metric1\").\n......\n\n// Create the Document\nmetricprovider.sync(true);",
            "title": "3. UPDATE"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#4-delete",
            "text": "Mongo mongo = new Mongo();\nmongo.dropDatabase(\"databasename\");",
            "title": "4. DELETE"
        },
        {
            "location": "/admin/Access-to-MongoDB-database-using-PONGO/#comment",
            "text": "This wiki has dealt with the access of MongoDB database using PONGO. To continue learning how to modify and make a new model with Pongo, we have another page here  link  .",
            "title": "Comment"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/",
            "text": "When to use ?\n\n\nIn this guideline, we describe ways to extend the CROSSMINER data model with the existing architecture of CROSSMINER. These guidelines are needed to keep order  the data layer of CROSSMINER platform during the evolution.\n\n\nContext\n\n\nThe CROSSMINER platform use MongoBb as database. The access to the database is managed using the Pongo , a framework which manage the mapping between MongoDb documents and Java class. \n\n\nEach MongoDb document is mapped on a Java class which which extend the Pongo class.This Java class are generated form an emf file which describe the data model. \n\n\nThe current data model is composed of multiple documents which are mapped to several Pongo classes. This Java classes are organized in plugins : \n\n\n\n\nThe Platform data model (org.ossmeter.repository.model)\n : Contains data related to project administration ,  metric execution process and authentification system.\n\n\nSource Code Repositroy managers (org.ossmeter.repository.model.'project delta manager')\n : Contains configuration informations related to source codes managemeny tools.\n\n\nMetric Providers data models (in each metric provider plugins)\n :  Each metric provider implementation contains his once data model.\n\n\n\n\nYou need to Extend an Existing Data Model ?\n\n\nThe first way would be to make changes directly in the existing model. This option is to be used carefully as it may affect the rest of the platform modules. Therefore, it must be well checked, such that the rest of the part of the platform remains the same.\n\n\n1. Locate the *.emf file of this data model\n\n\nA presented previously, the Pongo Java class are generated form and EMF file which describe the data model. The file can be found in the implementaion plugin of each data model.\n\n\nEx : the platform data model Definition File can be find on the org.ossmeter.repository.model plugin (/src/org/ossmeter/repository/model/ossmeter.emf)\n\n\n2. Update the Data  Model description\n\n\nA data model description file contains a statical description of a MongoDb document.\n\n\n@db\nclass ProjectRepository extends NamedElement {\n  val Project[*] projects;\n  val Role[*] roles;\n  .\n  val ProjectError[*] errors;\n}\n\n@customize\nclass ProjectError {\n    attr Date date;\n        .\n    attr String stackTrace;\n}\n...\n\n\n\n\nIf we would like to add one more attribute to the element \nProjectError\n, we could add it this way :\n\n\n@db\nclass ProjectRepository extends NamedElement {\n  val Project[*] projects;\n  val Role[*] roles;\n  .\n  val ProjectError[*] errors;\n}\n\n@customize\nclass ProjectError {\n    attr Date date;\n        .\n        .\n        .\n    attr String stackTrace;\n+       attr String TestAttribute;\n}\n...\n\n\n\n\nYou can find more information about the data model description syntax at this url : https://github.com/kolovos/pongo/wiki/Model-Design-Guidelines\n\n\n3. Generate the Java Class using the Pongo Tool.\n\n\n\n\nDownload the Pongo tool : https://github.com/kolovos/pongo/releases\n\n\nRun the Pongo generator from the command line as follows: \njava -jar pongo.jar  youremffile.emf\n\n\nReplace the existing Java class by the new generated java class.\n\n\n\n\nMore information about Pongo  : https://github.com/kolovos/pongo/wiki\n\n\nYou need to Create a new Data Model ?\n\n\nThe second way is to evolve the data model by building a new model/ database/ collection in Mongodb. This pongo model is separate from the existing model with separate database and thus avoids issues of breaking the existing model.\n\n\nIn this case, we invite you to create a new plugin which will contain your data model.\n\n\n1. Create a new Eclipse Plug-In\n\n\n\n\nCreate a new Eclipse Plug-In Project (\n\n\nIn Eclipse Toolbar : File > New > Plug-In Project\n\n\nName of the project : org.crossminer.\nmycomponent\n.repository.model\n\n\nDisable the generation of an Activator Class / contribution to the ui\n\n\nEdit the MANIFEST.MF file\n\n\nIn Dependency : add a dependency to the \norg.eclipse.core.runtime\n plugin\n\n\nIn Dependency : add a dependency to the \ncom.googlecode.pongo.runtime\n plugin\n\n\nIn Dependency : add a dependency to the \norg.apache.commons.lang3\n plugin\n\n\nIn Extentions : reference an extension point named \ncom.googlecode.pongo.runtime.osgi\n\n\nIn source directory\n\n\nCreate a package named org.crossminer.\nmycomponent\n.repository.model\n\n\nIn this package create an emf file named \nmycomponent.emf\n\n\n\n\nA presented previously, the Pongo Java class are generated form and EMF file which describe the data model.Define your data model in this file :\n\n\n```package org.crossminer.mycomponent.repository.model;\n\n\n@db \nclass MyComponent { \n     .... \n}\n```\nYou can find more information about the data model description syntax at this url : https://github.com/kolovos/pongo/wiki/Model-Design-Guidelines\n\n\n2. Generate the Java Class using the Pongo Tool.\n\n\n\n\nDownload the Pongo tool : https://github.com/kolovos/pongo/releases\n\n\nRun the Pongo generator from the command line as follows: \njava -jar pongo.jar  youremffile.emf\n\n\nAdd this class in your org.crossminer.\nmycomponent\n.repository.model package\n\n\n\n\nMore information about Pongo  : https://github.com/kolovos/pongo/wiki\n\n\nComment\n\n\nHere we learnt ways to modify model in the Crossminer platform. To know more about the access of data with the Pongo APIs \nlink here\n .",
            "title": "Extend MongoDB Data Model"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#when-to-use",
            "text": "In this guideline, we describe ways to extend the CROSSMINER data model with the existing architecture of CROSSMINER. These guidelines are needed to keep order  the data layer of CROSSMINER platform during the evolution.",
            "title": "When to use ?"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#context",
            "text": "The CROSSMINER platform use MongoBb as database. The access to the database is managed using the Pongo , a framework which manage the mapping between MongoDb documents and Java class.   Each MongoDb document is mapped on a Java class which which extend the Pongo class.This Java class are generated form an emf file which describe the data model.   The current data model is composed of multiple documents which are mapped to several Pongo classes. This Java classes are organized in plugins :    The Platform data model (org.ossmeter.repository.model)  : Contains data related to project administration ,  metric execution process and authentification system.  Source Code Repositroy managers (org.ossmeter.repository.model.'project delta manager')  : Contains configuration informations related to source codes managemeny tools.  Metric Providers data models (in each metric provider plugins)  :  Each metric provider implementation contains his once data model.",
            "title": "Context"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#you-need-to-extend-an-existing-data-model",
            "text": "The first way would be to make changes directly in the existing model. This option is to be used carefully as it may affect the rest of the platform modules. Therefore, it must be well checked, such that the rest of the part of the platform remains the same.",
            "title": "You need to Extend an Existing Data Model ?"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#1-locate-the-emf-file-of-this-data-model",
            "text": "A presented previously, the Pongo Java class are generated form and EMF file which describe the data model. The file can be found in the implementaion plugin of each data model.  Ex : the platform data model Definition File can be find on the org.ossmeter.repository.model plugin (/src/org/ossmeter/repository/model/ossmeter.emf)",
            "title": "1. Locate the *.emf file of this data model"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#2-update-the-data-model-description",
            "text": "A data model description file contains a statical description of a MongoDb document.  @db\nclass ProjectRepository extends NamedElement {\n  val Project[*] projects;\n  val Role[*] roles;\n  .\n  val ProjectError[*] errors;\n}\n\n@customize\nclass ProjectError {\n    attr Date date;\n        .\n    attr String stackTrace;\n}\n...  If we would like to add one more attribute to the element  ProjectError , we could add it this way :  @db\nclass ProjectRepository extends NamedElement {\n  val Project[*] projects;\n  val Role[*] roles;\n  .\n  val ProjectError[*] errors;\n}\n\n@customize\nclass ProjectError {\n    attr Date date;\n        .\n        .\n        .\n    attr String stackTrace;\n+       attr String TestAttribute;\n}\n...  You can find more information about the data model description syntax at this url : https://github.com/kolovos/pongo/wiki/Model-Design-Guidelines",
            "title": "2. Update the Data  Model description"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#3-generate-the-java-class-using-the-pongo-tool",
            "text": "Download the Pongo tool : https://github.com/kolovos/pongo/releases  Run the Pongo generator from the command line as follows:  java -jar pongo.jar  youremffile.emf  Replace the existing Java class by the new generated java class.   More information about Pongo  : https://github.com/kolovos/pongo/wiki",
            "title": "3. Generate the Java Class using the Pongo Tool."
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#you-need-to-create-a-new-data-model",
            "text": "The second way is to evolve the data model by building a new model/ database/ collection in Mongodb. This pongo model is separate from the existing model with separate database and thus avoids issues of breaking the existing model.  In this case, we invite you to create a new plugin which will contain your data model.",
            "title": "You need to Create a new Data Model ?"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#1-create-a-new-eclipse-plug-in",
            "text": "Create a new Eclipse Plug-In Project (  In Eclipse Toolbar : File > New > Plug-In Project  Name of the project : org.crossminer. mycomponent .repository.model  Disable the generation of an Activator Class / contribution to the ui  Edit the MANIFEST.MF file  In Dependency : add a dependency to the  org.eclipse.core.runtime  plugin  In Dependency : add a dependency to the  com.googlecode.pongo.runtime  plugin  In Dependency : add a dependency to the  org.apache.commons.lang3  plugin  In Extentions : reference an extension point named  com.googlecode.pongo.runtime.osgi  In source directory  Create a package named org.crossminer. mycomponent .repository.model  In this package create an emf file named  mycomponent.emf   A presented previously, the Pongo Java class are generated form and EMF file which describe the data model.Define your data model in this file :  ```package org.crossminer.mycomponent.repository.model;  @db \nclass MyComponent { \n     .... \n}\n```\nYou can find more information about the data model description syntax at this url : https://github.com/kolovos/pongo/wiki/Model-Design-Guidelines",
            "title": "1. Create a new Eclipse Plug-In"
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#2-generate-the-java-class-using-the-pongo-tool",
            "text": "Download the Pongo tool : https://github.com/kolovos/pongo/releases  Run the Pongo generator from the command line as follows:  java -jar pongo.jar  youremffile.emf  Add this class in your org.crossminer. mycomponent .repository.model package   More information about Pongo  : https://github.com/kolovos/pongo/wiki",
            "title": "2. Generate the Java Class using the Pongo Tool."
        },
        {
            "location": "/admin/Extend-MongoDB-Data-Model/#comment",
            "text": "Here we learnt ways to modify model in the Crossminer platform. To know more about the access of data with the Pongo APIs  link here  .",
            "title": "Comment"
        },
        {
            "location": "/admin/Platform-configuration/",
            "text": "When starting the platform, you can pass a configuration file to control the behaviour of the platform:\n\n\n./eclipse -slave -config myconfiguration.properties\n\n\n\n\nThe configuration file is a typical Java properties file. The properties that can be configured are:\n\n\nidentifier=<your name>\n\n\nThe identifier of the node. If not specified, the platform will attempt to use the node's hostname, and if it cannot resolve the hostname, it will generated a random UUID. \n\n\nIf you plan to multiple instances of the platform on the same machine, you should definitely specify different node identifiers.\n\n\nlog.type=console|file|rolling\n\n\nYou can specify whether to log output to the console (Log4J's ConsoleAppender), to a particular file without a size limit (Log4J's FileAppender), or to a different file per day (Log4J's DailyRollingFileAppender). If you specify \nfile\n or \nrolling\n, you must complete the \nlog.file.path\n or \nlog.rolling.path\n property as well. \n\n\nIf the property is not specified, it will default to the console logger.\n\n\nlog.file.path=<path>\n\n\nThe path to the file to store the log. E.g. \nlog.file.path=/tmp/lovelylog.log\n\n\nlog.rolling.path=<path>\n\n\nThe path to the file to store the log. This is a Log4J DailyRollingFileAppender that will create separate logs for each 12 hours of the day. The date stamp will be appended to the path provided. E.g.: if you specify \nlog.rolling.path=/tmp/mylovelylog.log\n, it will store files like so: \n/tmp/mylovelylog.log.2014-12-17-00\n and \n/tmp/mylovelylog.log.2014-12-17-12\n.\n\n\nmaven_executable=<path>\n\n\nThe path to where Maven is installed. E.g. \nmaven_executable=/usr/bin/mvn\n\n\nstorage_path=<path>\n\n\nThe path to where files should be stored. E.g. \nstorage_path=/mnt/ossmeter/\n\n\nmongo_hosts\n\n\nA comma-separated list of the hosts and ports in a replica set. E.g. \nua002:27017,ua009:27017,ua019:27017,ua020:27017",
            "title": "Platform configuration"
        },
        {
            "location": "/admin/Platform-configuration/#identifieryour-name",
            "text": "The identifier of the node. If not specified, the platform will attempt to use the node's hostname, and if it cannot resolve the hostname, it will generated a random UUID.   If you plan to multiple instances of the platform on the same machine, you should definitely specify different node identifiers.",
            "title": "identifier=&lt;your name&gt;"
        },
        {
            "location": "/admin/Platform-configuration/#logtypeconsolefilerolling",
            "text": "You can specify whether to log output to the console (Log4J's ConsoleAppender), to a particular file without a size limit (Log4J's FileAppender), or to a different file per day (Log4J's DailyRollingFileAppender). If you specify  file  or  rolling , you must complete the  log.file.path  or  log.rolling.path  property as well.   If the property is not specified, it will default to the console logger.",
            "title": "log.type=console|file|rolling"
        },
        {
            "location": "/admin/Platform-configuration/#logfilepathpath",
            "text": "The path to the file to store the log. E.g.  log.file.path=/tmp/lovelylog.log",
            "title": "log.file.path=&lt;path&gt;"
        },
        {
            "location": "/admin/Platform-configuration/#logrollingpathpath",
            "text": "The path to the file to store the log. This is a Log4J DailyRollingFileAppender that will create separate logs for each 12 hours of the day. The date stamp will be appended to the path provided. E.g.: if you specify  log.rolling.path=/tmp/mylovelylog.log , it will store files like so:  /tmp/mylovelylog.log.2014-12-17-00  and  /tmp/mylovelylog.log.2014-12-17-12 .",
            "title": "log.rolling.path=&lt;path&gt;"
        },
        {
            "location": "/admin/Platform-configuration/#maven_executablepath",
            "text": "The path to where Maven is installed. E.g.  maven_executable=/usr/bin/mvn",
            "title": "maven_executable=&lt;path&gt;"
        },
        {
            "location": "/admin/Platform-configuration/#storage_pathpath",
            "text": "The path to where files should be stored. E.g.  storage_path=/mnt/ossmeter/",
            "title": "storage_path=&lt;path&gt;"
        },
        {
            "location": "/admin/Platform-configuration/#mongo_hosts",
            "text": "A comma-separated list of the hosts and ports in a replica set. E.g.  ua002:27017,ua009:27017,ua019:27017,ua020:27017",
            "title": "mongo_hosts"
        },
        {
            "location": "/admin/SCAVA-Administration/",
            "text": "The SCAVA administration dashboard take care of:\n\n Provide user administration feature, including user profile activation service and roles based authorization management.\n\n Provide services to analyse automatically open source software projects.\n\n\nAdministration Dashboard Installation\n\n\nPrerequired\n\n\nThe SCAVA administration dashboard  is front end web application based on Angular Framework. It can be executed in both Linux or Windows systems where it's required the installation of the following tools:\n\n\nNode.js\n\n\n\n\nDownload Node.js ver. 8.11.2 (includes npm 5.6.0) or above : https://nodejs.org/en/download/\n\n\n\n\nYarn Package Manager\n\n\n\n\nDownload Yarn ver. 1.7.0 or above : https://yarnpkg.com\n\n\n\n\nGet Started Scava Administration\n\n\nScava Administration is a single page web application based on Angular 6 Framework. To get started with Angular, it's better to install Angular CLI tool to make application development more quicker and easier (Find more here: https://angular.io/guide/quickstart).\n\n\nScava Dashboard Deployment\n\n\nIn order to deploy the Scava Administration, you must to build and copy the output directory to a web server (For instance Apache HTTP Server).\n\n\nUsing the development profile:\n\n\n\n\nExecute the development build using the Angular CLI command line : \nng build\n.\n\n\nCopy everything within the output folder (dist/ by default) to a folder on the server.\n\n\nIf you copy the files into a server sub-folder, append the build flag, --base-href and set the \n appropriately. For example, if the index.html is on the server at /administration/index.html, set the base href to \n like this. or simply you can run: \nng build --base-href=/administration/\n\n\n\n\nUsing the production profile:\n\n\n\n\nYou can generate an optimized build with additional CLI command line flags: \nng build -- prod\n.\n\n\nCopy everything within the output folder (dist/ by default) to a folder on the server.\n\n\nIf you copy the files into a server sub-folder, append the build flag, --base-href and set the \n appropriately. For example, if the index.html is on the server at /administration/index.html, set the base href to \n like this. or simply you can run: \nng build --base-href=/administration/\n.",
            "title": "SCAVA Administration"
        },
        {
            "location": "/admin/SCAVA-Administration/#administration-dashboard-installation",
            "text": "",
            "title": "Administration Dashboard Installation"
        },
        {
            "location": "/admin/SCAVA-Administration/#prerequired",
            "text": "The SCAVA administration dashboard  is front end web application based on Angular Framework. It can be executed in both Linux or Windows systems where it's required the installation of the following tools:",
            "title": "Prerequired"
        },
        {
            "location": "/admin/SCAVA-Administration/#nodejs",
            "text": "Download Node.js ver. 8.11.2 (includes npm 5.6.0) or above : https://nodejs.org/en/download/",
            "title": "Node.js"
        },
        {
            "location": "/admin/SCAVA-Administration/#yarn-package-manager",
            "text": "Download Yarn ver. 1.7.0 or above : https://yarnpkg.com",
            "title": "Yarn Package Manager"
        },
        {
            "location": "/admin/SCAVA-Administration/#get-started-scava-administration",
            "text": "Scava Administration is a single page web application based on Angular 6 Framework. To get started with Angular, it's better to install Angular CLI tool to make application development more quicker and easier (Find more here: https://angular.io/guide/quickstart).",
            "title": "Get Started Scava Administration"
        },
        {
            "location": "/admin/SCAVA-Administration/#scava-dashboard-deployment",
            "text": "In order to deploy the Scava Administration, you must to build and copy the output directory to a web server (For instance Apache HTTP Server).",
            "title": "Scava Dashboard Deployment"
        },
        {
            "location": "/admin/SCAVA-Administration/#using-the-development-profile",
            "text": "Execute the development build using the Angular CLI command line :  ng build .  Copy everything within the output folder (dist/ by default) to a folder on the server.  If you copy the files into a server sub-folder, append the build flag, --base-href and set the   appropriately. For example, if the index.html is on the server at /administration/index.html, set the base href to   like this. or simply you can run:  ng build --base-href=/administration/",
            "title": "Using the development profile:"
        },
        {
            "location": "/admin/SCAVA-Administration/#using-the-production-profile",
            "text": "You can generate an optimized build with additional CLI command line flags:  ng build -- prod .  Copy everything within the output folder (dist/ by default) to a folder on the server.  If you copy the files into a server sub-folder, append the build flag, --base-href and set the   appropriately. For example, if the index.html is on the server at /administration/index.html, set the base href to   like this. or simply you can run:  ng build --base-href=/administration/ .",
            "title": "Using the production profile:"
        },
        {
            "location": "/architecture/API-Gateway-Component/",
            "text": "The API Gateway component\n\n\nThe CROSSMIER API Gateway :\n\n\n\n\nProvide a centralized access point to all web services implemented by the differents tools involved in the platform (DevOps Dashboard,Workflow Execution Engine,Knowledge Base,Metric Provider,Administration Application).\n\n\nProvide a centralized mechanisms to secuerize CROSSMINER web services and manage authentication  required to access to this services.\n\n\n\n\nAPI Gateway Architecture\n\n\nThe API Gateway  is a pattern which come form microserivces echosystem. An API Gateway is a single point of entry (and control) for front end clients, which could be browser based or mobile. The client only has to know the URL of one server, and the backend can be refactored at will with no change.\n\n\nThe API Gateway act as a revers web proxy in which can be integrated others functions like load balancing and authentication. In case of the CROSSMINER platform, the  API Gateway will manage the authentication for all services of the platform.  \n\n\n\n\nAuthentication Mechanism\n\n\nJSON Web Tokens\n\n\nThe CROSSMIER API Gateway is secruized using JSON Web Tokens (JWT) mechanism, an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object.\n\n\nIn authentication, when the user successfully logs in using their credentials, a JSON Web Token will be returned and must be saved locally, instead of the traditional approach of creating a session in the server and returning a cookie.When the client request an access to a protected service ,the server's protected routes will check for a valid JWT in the Authorization header of the request, and if it's present, the user will be allowed to access protected resources. (More about JWT : https://jwt.io)\n\n\n\n\nAuthentication Architecture\n\n\nIn CROSSMINER, the authentification service is a sub component of the Administration Application which centralise Right Management for the whole platform. As for the others services, the authentication service is accessed behind the API Gateway.\n\n\n\n\nAuthentication Flow\n\n\n\n\nTo obtain an access to a specific service, the client must authenticate with the authentication service.If the authentication success,he recived a web token that should be include in the header of all of his future requests.\n\n\nWhen the client request a specific service, the api gateway valivate the token from the authentication  service. If the token is valide, the api gateway transmite the request to the related service.\n\n\n\n\n\n\nImplementation\n\n\nThe implementation of the gateway is based on Zuul proxy, a component of the spring-cloud project, an extention ofthe spring framework dedicated to microservices architectures.\n\n\nhttps://projects.spring.io/spring-cloud/spring-cloud.html#_router_and_filter_zuul\n\n\nAPI Gateway Configuration\n\n\nThe CROSSMINER Gateway can be configured by the intermediary of an external property file (application.properties) to place in the execution directory of the CROSSMINER Gateway component. This file allow to configure the routing of requests send to the gateway an some security parameters.\n\n\nServer Configuration\n\n\n\n\nid : \nserver.port\ndefault :\n 8086\n\n\nPort of the CORSSMINER API server. Each REST request sent to the gateway must be addressed to this port.\n\n\n\n\n\nJWT Security Configuration\n\n\n\n\nid : \napigateway.security.jwt.secret\ndefault :\n NA\n\n\nPrivate key pair which allow to sign jwt tokens using RSA.\n\n\n\n\n\n\n\nid : \napigateway.security.jwt.url\ndefault :\n /login\n\n\nURL Path of the authentication service.\n\n\n\n\n\n\n\nid : \napigateway.security.jwt.expiration\ndefault :\n 86400 (24H)\n\n\nPort of the CORSSMINER API server. Each request sent to the gateway must be addressed to this port.\n\n\n\n\n\nRouting : Authentication Service Configuration\n\n\n\n\nid : \nzuul.routes.auth-center.path\ndefault :\n /api/authentication/**\n\n\nRelative path of the authentication service.\n\n\n\n\n\n\n\nid : \nzuul.routes.auth-center.url\ndefault :\n NA\n\n\nURL of the authentification server. Example :http://127.0.0.1:8081/ \n\n\n\n\n\n\n\nid : \nzuul.routes.auth-center.sensitiveHeaders\ndefault :\n Cookie,Set-Cookie\n\n\nSpecify a list of ignored headers as part of the route configuration which will be not leaking downstream into external servers.\n\n\n\n\n\n\n\nid : \nzuul.routes.auth-center.stripPrefix\ndefault :\n false\n\n\nSwitch off the stripping of the service-specific prefix from individual routes\n\n\n\n\n\nRouting : Service Configuration\n\n\n\n\nid : \nzuul.routes.**servicename**.path\ndefault :\n NA\n\n\nRelative path of the incoming service which will be redirected. Example : /test1/**\n\n\n\n\n\n\n\nid : \nzuul.routes.**servicename**.url\ndefault :\n NA\n\n\nRedirection URL of the route. Example : http://127.0.0.1:8082/test1\n\n\n\n\n\nConfiguration file example\n\n\n#API Gateway Port\nserver.port=8086\n\n# JWT Configuration\napigateway.security.jwt.secret=otherpeopledontknowit\napigateway.security.jwt.url=/api/authentication\napigateway.security.jwt.expiration=86400\n\n# Rooting Configuration : Authentication Service\nzuul.routes.auth-center.path=/api/authentication/**\nzuul.routes.auth-center.url=http://127.0.0.1:8081/\nzuul.routes.auth-center.sensitiveHeaders=Cookie,Set-Cookie\nzuul.routes.auth-center.stripPrefix=false\n\n\n# Rooting Configuration : Test1 Service\nzuul.routes.test1.path=/test1/**\nzuul.routes.test1.url=http://127.0.0.1:8082/test1\n\n# Rooting Configuration : Test2 Service\nzuul.routes.test2.path=/test2/**\nzuul.routes.test2.url=http://127.0.0.1:8083/test2\n\n\n\n\nControl access API\n\n\nThe CROSSMINER platform comes with public and private APIs to control the access to the REST API using different permission levels. By default, there are three authorization levels which are predefined to get access to all the CROSSMINER's APIS, including:\n\n \u201cROLE_ADMIN\u201d\n\n \u201cROLE_PROJECT_MANAGER\u201d\n* \u201cROLE_USER\u201d\n\n\nBy the way, The frontend SCAVA administration comes with a default \u201cadmin\u201d who is mainly the admin user with all authorities access including \u201cROLE_ADMIN\u201d, \u201cROLE_PROJECT_MANAGER\u201d and \u201cROLE_USER\u201d authorizations. His default password is \u201cadmin\u201d.\n\n\n# Filtering private restApi\n\nscava.routes.config.adminAccessApi[0]=/api/users\nscava.routes.config.adminAccessApi[1]=/api/user/**\n\nscava.routes.config.projectManagerAccessApi[0]=/administration/projects/create\nscava.routes.config.projectManagerAccessApi[1]=/administration/projects/import\nscava.routes.config.projectManagerAccessApi[2]=/administration/analysis/**\n\nscava.routes.config.userAccessApi[0]=/administration/projects\nscava.routes.config.userAccessApi[1]=/administration/projects/p/**\nscava.routes.config.userAccessApi[2]=/api/users/**\nscava.routes.config.userAccessApi[3]=/api/account\n\n\n\n\nPackaging Form Sources\n\n\nMaven Packaging\n\n\nmvn -Pprod install\n\n\n\n\nAPI Gateway Execution\n\n\n\n\ncomplete an put the \"application.properties\" configuration file in the execute directory.\n\n\nExecute the crossmeter-api-gateway-1.0.0.jar Jar.\n\n\n\n\njava -jar scava-api-gateway-1.0.0.jar\n\n\n\n\nClient Implementation\n\n\n\n\n[[How to consume a CROSSMINER REST services ? | Consuming REST Services]]\n\n\nThis guideline is dedicated to clients which would like to used CORSSMINER REST Services.It adress authentication issues",
            "title": "API Gateway Component"
        },
        {
            "location": "/architecture/API-Gateway-Component/#the-api-gateway-component",
            "text": "The CROSSMIER API Gateway :   Provide a centralized access point to all web services implemented by the differents tools involved in the platform (DevOps Dashboard,Workflow Execution Engine,Knowledge Base,Metric Provider,Administration Application).  Provide a centralized mechanisms to secuerize CROSSMINER web services and manage authentication  required to access to this services.",
            "title": "The API Gateway component"
        },
        {
            "location": "/architecture/API-Gateway-Component/#api-gateway-architecture",
            "text": "The API Gateway  is a pattern which come form microserivces echosystem. An API Gateway is a single point of entry (and control) for front end clients, which could be browser based or mobile. The client only has to know the URL of one server, and the backend can be refactored at will with no change.  The API Gateway act as a revers web proxy in which can be integrated others functions like load balancing and authentication. In case of the CROSSMINER platform, the  API Gateway will manage the authentication for all services of the platform.",
            "title": "API Gateway Architecture"
        },
        {
            "location": "/architecture/API-Gateway-Component/#authentication-mechanism",
            "text": "",
            "title": "Authentication Mechanism"
        },
        {
            "location": "/architecture/API-Gateway-Component/#json-web-tokens",
            "text": "The CROSSMIER API Gateway is secruized using JSON Web Tokens (JWT) mechanism, an open standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object.  In authentication, when the user successfully logs in using their credentials, a JSON Web Token will be returned and must be saved locally, instead of the traditional approach of creating a session in the server and returning a cookie.When the client request an access to a protected service ,the server's protected routes will check for a valid JWT in the Authorization header of the request, and if it's present, the user will be allowed to access protected resources. (More about JWT : https://jwt.io)",
            "title": "JSON Web Tokens"
        },
        {
            "location": "/architecture/API-Gateway-Component/#authentication-architecture",
            "text": "In CROSSMINER, the authentification service is a sub component of the Administration Application which centralise Right Management for the whole platform. As for the others services, the authentication service is accessed behind the API Gateway.",
            "title": "Authentication Architecture"
        },
        {
            "location": "/architecture/API-Gateway-Component/#authentication-flow",
            "text": "To obtain an access to a specific service, the client must authenticate with the authentication service.If the authentication success,he recived a web token that should be include in the header of all of his future requests.  When the client request a specific service, the api gateway valivate the token from the authentication  service. If the token is valide, the api gateway transmite the request to the related service.",
            "title": "Authentication Flow"
        },
        {
            "location": "/architecture/API-Gateway-Component/#implementation",
            "text": "The implementation of the gateway is based on Zuul proxy, a component of the spring-cloud project, an extention ofthe spring framework dedicated to microservices architectures.  https://projects.spring.io/spring-cloud/spring-cloud.html#_router_and_filter_zuul",
            "title": "Implementation"
        },
        {
            "location": "/architecture/API-Gateway-Component/#api-gateway-configuration",
            "text": "The CROSSMINER Gateway can be configured by the intermediary of an external property file (application.properties) to place in the execution directory of the CROSSMINER Gateway component. This file allow to configure the routing of requests send to the gateway an some security parameters.",
            "title": "API Gateway Configuration"
        },
        {
            "location": "/architecture/API-Gateway-Component/#server-configuration",
            "text": "id :  server.port default :  8086  Port of the CORSSMINER API server. Each REST request sent to the gateway must be addressed to this port.",
            "title": "Server Configuration"
        },
        {
            "location": "/architecture/API-Gateway-Component/#jwt-security-configuration",
            "text": "id :  apigateway.security.jwt.secret default :  NA  Private key pair which allow to sign jwt tokens using RSA.    id :  apigateway.security.jwt.url default :  /login  URL Path of the authentication service.    id :  apigateway.security.jwt.expiration default :  86400 (24H)  Port of the CORSSMINER API server. Each request sent to the gateway must be addressed to this port.",
            "title": "JWT Security Configuration"
        },
        {
            "location": "/architecture/API-Gateway-Component/#routing-authentication-service-configuration",
            "text": "id :  zuul.routes.auth-center.path default :  /api/authentication/**  Relative path of the authentication service.    id :  zuul.routes.auth-center.url default :  NA  URL of the authentification server. Example :http://127.0.0.1:8081/     id :  zuul.routes.auth-center.sensitiveHeaders default :  Cookie,Set-Cookie  Specify a list of ignored headers as part of the route configuration which will be not leaking downstream into external servers.    id :  zuul.routes.auth-center.stripPrefix default :  false  Switch off the stripping of the service-specific prefix from individual routes",
            "title": "Routing : Authentication Service Configuration"
        },
        {
            "location": "/architecture/API-Gateway-Component/#routing-service-configuration",
            "text": "id :  zuul.routes.**servicename**.path default :  NA  Relative path of the incoming service which will be redirected. Example : /test1/**    id :  zuul.routes.**servicename**.url default :  NA  Redirection URL of the route. Example : http://127.0.0.1:8082/test1",
            "title": "Routing : Service Configuration"
        },
        {
            "location": "/architecture/API-Gateway-Component/#configuration-file-example",
            "text": "#API Gateway Port\nserver.port=8086\n\n# JWT Configuration\napigateway.security.jwt.secret=otherpeopledontknowit\napigateway.security.jwt.url=/api/authentication\napigateway.security.jwt.expiration=86400\n\n# Rooting Configuration : Authentication Service\nzuul.routes.auth-center.path=/api/authentication/**\nzuul.routes.auth-center.url=http://127.0.0.1:8081/\nzuul.routes.auth-center.sensitiveHeaders=Cookie,Set-Cookie\nzuul.routes.auth-center.stripPrefix=false\n\n\n# Rooting Configuration : Test1 Service\nzuul.routes.test1.path=/test1/**\nzuul.routes.test1.url=http://127.0.0.1:8082/test1\n\n# Rooting Configuration : Test2 Service\nzuul.routes.test2.path=/test2/**\nzuul.routes.test2.url=http://127.0.0.1:8083/test2",
            "title": "Configuration file example"
        },
        {
            "location": "/architecture/API-Gateway-Component/#control-access-api",
            "text": "The CROSSMINER platform comes with public and private APIs to control the access to the REST API using different permission levels. By default, there are three authorization levels which are predefined to get access to all the CROSSMINER's APIS, including:  \u201cROLE_ADMIN\u201d  \u201cROLE_PROJECT_MANAGER\u201d\n* \u201cROLE_USER\u201d  By the way, The frontend SCAVA administration comes with a default \u201cadmin\u201d who is mainly the admin user with all authorities access including \u201cROLE_ADMIN\u201d, \u201cROLE_PROJECT_MANAGER\u201d and \u201cROLE_USER\u201d authorizations. His default password is \u201cadmin\u201d.  # Filtering private restApi\n\nscava.routes.config.adminAccessApi[0]=/api/users\nscava.routes.config.adminAccessApi[1]=/api/user/**\n\nscava.routes.config.projectManagerAccessApi[0]=/administration/projects/create\nscava.routes.config.projectManagerAccessApi[1]=/administration/projects/import\nscava.routes.config.projectManagerAccessApi[2]=/administration/analysis/**\n\nscava.routes.config.userAccessApi[0]=/administration/projects\nscava.routes.config.userAccessApi[1]=/administration/projects/p/**\nscava.routes.config.userAccessApi[2]=/api/users/**\nscava.routes.config.userAccessApi[3]=/api/account",
            "title": "Control access API"
        },
        {
            "location": "/architecture/API-Gateway-Component/#packaging-form-sources",
            "text": "Maven Packaging  mvn -Pprod install",
            "title": "Packaging Form Sources"
        },
        {
            "location": "/architecture/API-Gateway-Component/#api-gateway-execution",
            "text": "complete an put the \"application.properties\" configuration file in the execute directory.  Execute the crossmeter-api-gateway-1.0.0.jar Jar.   java -jar scava-api-gateway-1.0.0.jar",
            "title": "API Gateway Execution"
        },
        {
            "location": "/architecture/API-Gateway-Component/#client-implementation",
            "text": "[[How to consume a CROSSMINER REST services ? | Consuming REST Services]]  This guideline is dedicated to clients which would like to used CORSSMINER REST Services.It adress authentication issues",
            "title": "Client Implementation"
        },
        {
            "location": "/architecture/Authentication-Component/",
            "text": "The CROSSMINER Authentication service:\n\n Provides a centralized mechanisms to securize CROSSMINER's components and manage authentication for all services of the platform.\n\n Provides user management services, including user registration process, user profile editing and roles based authorization management.\n\n\nAuthentication API\n\n\nThe Authentication server is a component of The CROSSMINER platform which manages the authentication for all  services accessible behind the API Gateway.\n\n\n\n\n[[Authenticate User|REST API : Authenticate User]]\nPOST\n/api/authentication\n\n\nLogin a registered user.\n\n\n\n\n\n\n\n### JSON Web Tokens (JWT)\nJSON Web Token (JWT) is an open industry standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. It consists of three parts separated by dots (.), which are:\n* Header\n* Payload\n* Signature\n\nThis solution uses a secure token that holds the information that we want to transmit and other information about our token, basically the user\u2019s **login name** and **authorities**. (Find more about JWT: https://jwt.io/).\n\n### JWT Authentication Implementation\n\n* Users have to login to the authentication service API using their credentials username and password.\n\n\u0002wzxhzdk:0\u0003\n\n* Once, the user authenticate, he will get a JWT token in the HTTP Response Authorization Header.\n\n\n\n\n* The generated token will be used by injecting it inside the HTTP Request Authorization Header to get access to the different CROSSMINER's components behind the API Gateway.\n\n\u0002wzxhzdk:1\u0003\n\n\n\n\n## User Management API\nThe Authentication component provides web services for CRUD user account.\n\n\n\n\n[[Register User|REST API : Register User]]\nPOST\n/api/register\n\n\nRegister new user.\n\n\n\n\n\n\n[[Activate User|Activate User]]\nGET\n/api/activate\n\n\nActivate the registered user.\n\n\n\n\n\n\n[[Update User|Update User]]\nPUT\n/api/users\n\n\nUpdate an existing user.\n\n\n\n\n\n\n[[Retrieve Users|Retrieve Users]]\nGET\n/api/users\n\n\nGet all registered users.\n\n\n\n\n\n\n[[Retrieve Login User|Retrieve Login User]]\nGET\n/api/users/{login}\n\n\nGet the \"login\" user.\n\n\n\n\n\n\n[[Delete User|Delete User]]\nDELETE\n/api/users/{login}\n\n\nDelete the \"login\" user.\n\n\n\n\n\nAuthentication Server Configuration\n\n\nThe Authentication server parametrize inside an external property file (application.properties) placed in the same execution directory of the Authentication component.\n\n\nServer Configuration\n\n\n\n\nid : \nserver.port\ndefault :\n 8085\n\n\nPort of the Authentication API server. Each REST request sent to the gateway must be adressed to this port.\n\n\n\n\n\nJWT Security Configuration\n\n\n\n\nid : \napigateway.security.jwt.secret\ndefault :\n NA\n\n\nPrivate key pair which allow to sign jwt tokens using RSA.\n\n\n\n\n\nDefault ADMIN configuration\n\n\n\n\n\n\n\n\nProperty\n\n\nDescription\n\n\nDefault Value\n\n\n\n\n\n\n\n\n\n\nscava.administration.username\n\n\nThe administrator username\n\n\nadmin\n\n\n\n\n\n\nscava.administration.password\n\n\nThe administrator password\n\n\nadmin\n\n\n\n\n\n\nscava.administration.admin-role\n\n\nThe admin role\n\n\nADMIN\n\n\n\n\n\n\nscava.administration.project-manager-role\n\n\nThe project manager role\n\n\nPROJECT_MANAGER\n\n\n\n\n\n\nscava.administration.project-user-role\n\n\nThe user role\n\n\nUSER\n\n\n\n\n\n\n\n\nMongodb Database Configuration\n\n\n\n\n\n\n\n\nProperty\n\n\nDescription\n\n\nDefault Value\n\n\n\n\n\n\n\n\n\n\nspring.data.mongodb.uri\n\n\nUrl of the MongoDB database server\n\n\nmongodb://localhost:27017\n\n\n\n\n\n\nspring.data.mongodb.database\n\n\nName of the MongoDB database\n\n\nscava\n\n\n\n\n\n\n\n\nMail Server configuration\n\n\nIn order to register new users, you have to configure a mail server.\n\n\n\n\n\n\n\n\nProperty\n\n\nDescription\n\n\nDefault Value\n\n\n\n\n\n\n\n\n\n\nspring.mail.host\n\n\nUrl of the mail service\n\n\nsmtp.gmail.com\n\n\n\n\n\n\nspring.mail.port\n\n\nPort of the mail service\n\n\n587\n\n\n\n\n\n\nspring.mail.username\n\n\nLogin of the mail account\n\n\n\n\n\n\n\n\nspring.mail.password\n\n\nPassword of the mail account\n\n\n\n\n\n\n\n\nspring.mail.protocol\n\n\nmail protocole\n\n\nsmtp\n\n\n\n\n\n\nspring.mail.tls\n\n\n-\n\n\ntrue\n\n\n\n\n\n\nspring.mail.properties.mail.smtp.auth\n\n\n-\n\n\ntrue\n\n\n\n\n\n\nspring.mail.properties.mail.smtp.starttls.enable\n\n\n-\n\n\ntrue\n\n\n\n\n\n\nspring.mail.properties.mail.smtp.ssl.trust=\n\n\n-\n\n\nsmtp.gmail.com\n\n\n\n\n\n\n\n\nAdministration Dashboard Setting\n\n\n\n\nid : \nscava.administration.base-url\ndefault :\n http://localhost:4200\n\n\nThe SCAVA administration base URL to generate the activation account URL.\n\n\n\n\n\nPackaging From Sources\n\n\nMaven Packaging\n\n\nmvn -Pprod install\n\n\n\n\nAuthentication Server Execution\n\n\n\n\ncomplete an put the \"application.properties\" configuration file in the execution directory. \n\n\nExecute the scava-auth-service-1.0.0.jar Jar.\n\n\n\n\njava -jar scava-auth-service-1.0.0.jar",
            "title": "Authentication Component"
        },
        {
            "location": "/architecture/Authentication-Component/#authentication-api",
            "text": "The Authentication server is a component of The CROSSMINER platform which manages the authentication for all  services accessible behind the API Gateway.   [[Authenticate User|REST API : Authenticate User]] POST /api/authentication  Login a registered user.   \n\n### JSON Web Tokens (JWT)\nJSON Web Token (JWT) is an open industry standard (RFC 7519) that defines a compact and self-contained way for securely transmitting information between parties as a JSON object. It consists of three parts separated by dots (.), which are:\n* Header\n* Payload\n* Signature\n\nThis solution uses a secure token that holds the information that we want to transmit and other information about our token, basically the user\u2019s **login name** and **authorities**. (Find more about JWT: https://jwt.io/).\n\n### JWT Authentication Implementation\n\n* Users have to login to the authentication service API using their credentials username and password.\n\n\u0002wzxhzdk:0\u0003\n\n* Once, the user authenticate, he will get a JWT token in the HTTP Response Authorization Header. \n\n* The generated token will be used by injecting it inside the HTTP Request Authorization Header to get access to the different CROSSMINER's components behind the API Gateway.\n\n\u0002wzxhzdk:1\u0003 \n\n## User Management API\nThe Authentication component provides web services for CRUD user account.  [[Register User|REST API : Register User]] POST /api/register  Register new user.    [[Activate User|Activate User]] GET /api/activate  Activate the registered user.    [[Update User|Update User]] PUT /api/users  Update an existing user.    [[Retrieve Users|Retrieve Users]] GET /api/users  Get all registered users.    [[Retrieve Login User|Retrieve Login User]] GET /api/users/{login}  Get the \"login\" user.    [[Delete User|Delete User]] DELETE /api/users/{login}  Delete the \"login\" user.",
            "title": "Authentication API"
        },
        {
            "location": "/architecture/Authentication-Component/#authentication-server-configuration",
            "text": "The Authentication server parametrize inside an external property file (application.properties) placed in the same execution directory of the Authentication component.",
            "title": "Authentication Server Configuration"
        },
        {
            "location": "/architecture/Authentication-Component/#server-configuration",
            "text": "id :  server.port default :  8085  Port of the Authentication API server. Each REST request sent to the gateway must be adressed to this port.",
            "title": "Server Configuration"
        },
        {
            "location": "/architecture/Authentication-Component/#jwt-security-configuration",
            "text": "id :  apigateway.security.jwt.secret default :  NA  Private key pair which allow to sign jwt tokens using RSA.",
            "title": "JWT Security Configuration"
        },
        {
            "location": "/architecture/Authentication-Component/#default-admin-configuration",
            "text": "Property  Description  Default Value      scava.administration.username  The administrator username  admin    scava.administration.password  The administrator password  admin    scava.administration.admin-role  The admin role  ADMIN    scava.administration.project-manager-role  The project manager role  PROJECT_MANAGER    scava.administration.project-user-role  The user role  USER",
            "title": "Default ADMIN configuration"
        },
        {
            "location": "/architecture/Authentication-Component/#mongodb-database-configuration",
            "text": "Property  Description  Default Value      spring.data.mongodb.uri  Url of the MongoDB database server  mongodb://localhost:27017    spring.data.mongodb.database  Name of the MongoDB database  scava",
            "title": "Mongodb Database Configuration"
        },
        {
            "location": "/architecture/Authentication-Component/#mail-server-configuration",
            "text": "In order to register new users, you have to configure a mail server.     Property  Description  Default Value      spring.mail.host  Url of the mail service  smtp.gmail.com    spring.mail.port  Port of the mail service  587    spring.mail.username  Login of the mail account     spring.mail.password  Password of the mail account     spring.mail.protocol  mail protocole  smtp    spring.mail.tls  -  true    spring.mail.properties.mail.smtp.auth  -  true    spring.mail.properties.mail.smtp.starttls.enable  -  true    spring.mail.properties.mail.smtp.ssl.trust=  -  smtp.gmail.com",
            "title": "Mail Server configuration"
        },
        {
            "location": "/architecture/Authentication-Component/#administration-dashboard-setting",
            "text": "id :  scava.administration.base-url default :  http://localhost:4200  The SCAVA administration base URL to generate the activation account URL.",
            "title": "Administration Dashboard Setting"
        },
        {
            "location": "/architecture/Authentication-Component/#packaging-from-sources",
            "text": "Maven Packaging  mvn -Pprod install",
            "title": "Packaging From Sources"
        },
        {
            "location": "/architecture/Authentication-Component/#authentication-server-execution",
            "text": "complete an put the \"application.properties\" configuration file in the execution directory.   Execute the scava-auth-service-1.0.0.jar Jar.   java -jar scava-auth-service-1.0.0.jar",
            "title": "Authentication Server Execution"
        },
        {
            "location": "/deploy/Docker-Ossmeter/",
            "text": "This page lists information about the Ossmeter docker image. It should be noted that the generated image uses the old \nOssmeter binaries\n and will not be updated -- all new development will go into the Crossminer repository.\n\n\nAll images are stored on the \nCrossminer Docker-hub account\n.\n\n\nThe Docker image is composed of 4 services: \n\n\n\n\noss-web: corresponds to the service of OSSMETER platform website.\n\n\noss-app: service running api server and the orchestrator of OSSMETER slave instances.\n\n\noss-slave: service corresponding to the OSSMETER slaves responsible for the analysis of software projects. There can be several slaves serving the same master for load balancing.\n\n\noss-db: service responsible for the the storage of OSSMETER data. Uses a MongoDB image.\n\n\n\n\nThe database comes pre-populated with a project and a user. The loaded dump comes from \nmd2manoppello's repo\n. Login information:\n\n\n\n\nuser: demo@crossminer.org\n\n\npassword: demo18\n\n\n\n\nCustom quality is in the user object (demo@crossminer.org) stored in the users collection of users db. It resembles the \ndemo quality model\n.\n\n\nRunning the Ossmeter docker image\n\n\nThe easiest way to build the full stack is to run the docker-compose file:\n\n\n$ docker-compose up\n\n\n\n\nThis command will download the images and run them. The application is then available on \nlocalhost:9000\n.\n\n\nBuilding the Ossmeter docker image\n\n\nTwo containers actually need to be built. They can be built individually.\n\n\noss-platform\n\n\nBuild the image from the oss-platform directory:\n\n\n$ docker build -t bbaldassari/ossmeter-platform .\nSending build context to Docker daemon  3.072kB\nStep 1/5 : FROM openjdk:8-jdk\n\n\n\n\noss-web\n\n\nBuild the image from the oss-web directory:\n\n\n$ docker build -t bbaldassari/ossmeter-web .\nSending build context to Docker daemon  3.072kB\nStep 1/7 : FROM openjdk:8-jre-alpine\n\n\n\n\nContinuous integration\n\n\nWe use Codefresh for the CI of our docker images. The latest demo instance of generated docker images can be found in the \n#ci\n channel in Slack.",
            "title": "Docker Ossmeter"
        },
        {
            "location": "/deploy/Docker-Ossmeter/#running-the-ossmeter-docker-image",
            "text": "The easiest way to build the full stack is to run the docker-compose file:  $ docker-compose up  This command will download the images and run them. The application is then available on  localhost:9000 .",
            "title": "Running the Ossmeter docker image"
        },
        {
            "location": "/deploy/Docker-Ossmeter/#building-the-ossmeter-docker-image",
            "text": "Two containers actually need to be built. They can be built individually.",
            "title": "Building the Ossmeter docker image"
        },
        {
            "location": "/deploy/Docker-Ossmeter/#oss-platform",
            "text": "Build the image from the oss-platform directory:  $ docker build -t bbaldassari/ossmeter-platform .\nSending build context to Docker daemon  3.072kB\nStep 1/5 : FROM openjdk:8-jdk",
            "title": "oss-platform"
        },
        {
            "location": "/deploy/Docker-Ossmeter/#oss-web",
            "text": "Build the image from the oss-web directory:  $ docker build -t bbaldassari/ossmeter-web .\nSending build context to Docker daemon  3.072kB\nStep 1/7 : FROM openjdk:8-jre-alpine",
            "title": "oss-web"
        },
        {
            "location": "/deploy/Docker-Ossmeter/#continuous-integration",
            "text": "We use Codefresh for the CI of our docker images. The latest demo instance of generated docker images can be found in the  #ci  channel in Slack.",
            "title": "Continuous integration"
        },
        {
            "location": "/deploy/Running-the-platform/",
            "text": "Running the platform\n\n\nThis is a quick start guide to get the OSSMETER platform running from source.\n\n\nAlthough these instructions may apply to other versions of Eclipse, they were tested under Eclipse Neon.3 with plug-in development support (Eclipse IDE for RCP Developers package).\n\n\nA step-by-step video guide is also available at \nhttps://youtu.be/3Ry4KKfNdYg\n\n\nStart MongoDB\n\n\nYou can download MongoDB from the \nMongoDb website\n.\n\n\nInstructions for starting mongo can be found in the MongoDB \nmanual\n. For example:\n\n\nmongod --dbpath /data/db --port 27017\n\n\n\n\nGet the Code\n\n\nGet the latest version of the code, and checkout the \ndev\n branch (please don't commit to the \nmaster\n branch: see [[Developer Guidelines|developer-guidelines]]):\n\n\nIf you are using \nLinux / OS X\n:\n\n\ngit clone https://github.com/crossminer/scava.git scava\ncd scava\ngit checkout dev\n\n\n\n\nIf you are using \nWindows\n you need to do things differently due to Windows' long file name limit. In the Git shell:\n\n\nmkdir scava\ncd scava\ngit init\ngit config core.longpaths true\ngit add remote origin https://github.com/crossminer/scava.git \ngit fetch\ngit checkout dev\n\n\n\n\nSetup Eclipse\n\n\nOpen Eclipse and import all projects from the top level directory of the CROSSMINER code (\nFile -> Import -> Existing projects into workspace\n), and wait for all the projects to compile without errors.\n\n\nValidate and Run the Platform\n\n\nOpen \norg.ossmeter.platform.osgi/ossmeterfromfeature.product\n\n  * Click the \nValidate...\n icon in the top right of the product configuration editor (the icon is a piece of paper with a tick)\n  * If things do not validate, there's something wrong -- get in touch :) Problems related to \norg.eclipse.e4.core.di\n aren't critical.\n  * Then, click the \nExport an Eclipse product\n on the left of the \nValidate...\n button. Uncheck the \nGenerate p2 repository\n checkbox, select a destination directory and validate. After a while, the OSSMETER platform will be generated in the selected directory.\n  * The platform can then be run using the generated \neclipse\n binary; it accepts the following arguments:\n    * \n-apiServer\n: Starts up the client API on localhost:8182\n    * \n-worker ${id-worker}\n: Spawns a thread that analyses registered projects\n  * To get a full platform running, first launch a master thread, then a slave, and finally the API server.\n\n\nIf you are developing code for the CROSSMINER platform, be sure to check out the [[Developer Guidelines|developer-guidelines]].\n\n\nRun the api-gateway\n\n\n\n\nRight click on \n\nscava-api-gateway/src/main/java/org.eclipse.scava.apigateway/ApiGatewayApplication.java\n\n\nThen click on Run As -> Java Application\n\n\n\n\nRun the authentication service\n\n\n\n\nRight click on \n\nscava-auth-service/src/main/java/org.eclipse.scava.authservice/AuthServiceApplication.java\n\n\nThen click on Run As -> Java Application\n\n\n\n\nRun the administration dashboard\n\n\nScava Administration is a single page web application based on Angular 6 Framework. To get started with Angular, it's better to install Angular CLI tool to make application development more quicker and easier (Find more here: https://angular.io/guide/quickstart).\n\n\nThe following instructions show how to run the dashboard web app:\n  * Enter the \nadministration/scava-administration/\n directory within the scava repository.\n  * Run the web app on port 4200 using angular-cli: \nng serve\n\n  * Navigate to \nhttp://localhost:4200/",
            "title": "Running the platform"
        },
        {
            "location": "/deploy/Running-the-platform/#running-the-platform",
            "text": "This is a quick start guide to get the OSSMETER platform running from source.  Although these instructions may apply to other versions of Eclipse, they were tested under Eclipse Neon.3 with plug-in development support (Eclipse IDE for RCP Developers package).  A step-by-step video guide is also available at  https://youtu.be/3Ry4KKfNdYg",
            "title": "Running the platform"
        },
        {
            "location": "/deploy/Running-the-platform/#start-mongodb",
            "text": "You can download MongoDB from the  MongoDb website .  Instructions for starting mongo can be found in the MongoDB  manual . For example:  mongod --dbpath /data/db --port 27017",
            "title": "Start MongoDB"
        },
        {
            "location": "/deploy/Running-the-platform/#get-the-code",
            "text": "Get the latest version of the code, and checkout the  dev  branch (please don't commit to the  master  branch: see [[Developer Guidelines|developer-guidelines]]):  If you are using  Linux / OS X :  git clone https://github.com/crossminer/scava.git scava\ncd scava\ngit checkout dev  If you are using  Windows  you need to do things differently due to Windows' long file name limit. In the Git shell:  mkdir scava\ncd scava\ngit init\ngit config core.longpaths true\ngit add remote origin https://github.com/crossminer/scava.git \ngit fetch\ngit checkout dev",
            "title": "Get the Code"
        },
        {
            "location": "/deploy/Running-the-platform/#setup-eclipse",
            "text": "Open Eclipse and import all projects from the top level directory of the CROSSMINER code ( File -> Import -> Existing projects into workspace ), and wait for all the projects to compile without errors.",
            "title": "Setup Eclipse"
        },
        {
            "location": "/deploy/Running-the-platform/#validate-and-run-the-platform",
            "text": "Open  org.ossmeter.platform.osgi/ossmeterfromfeature.product \n  * Click the  Validate...  icon in the top right of the product configuration editor (the icon is a piece of paper with a tick)\n  * If things do not validate, there's something wrong -- get in touch :) Problems related to  org.eclipse.e4.core.di  aren't critical.\n  * Then, click the  Export an Eclipse product  on the left of the  Validate...  button. Uncheck the  Generate p2 repository  checkbox, select a destination directory and validate. After a while, the OSSMETER platform will be generated in the selected directory.\n  * The platform can then be run using the generated  eclipse  binary; it accepts the following arguments:\n    *  -apiServer : Starts up the client API on localhost:8182\n    *  -worker ${id-worker} : Spawns a thread that analyses registered projects\n  * To get a full platform running, first launch a master thread, then a slave, and finally the API server.  If you are developing code for the CROSSMINER platform, be sure to check out the [[Developer Guidelines|developer-guidelines]].",
            "title": "Validate and Run the Platform"
        },
        {
            "location": "/deploy/Running-the-platform/#run-the-api-gateway",
            "text": "Right click on  scava-api-gateway/src/main/java/org.eclipse.scava.apigateway/ApiGatewayApplication.java  Then click on Run As -> Java Application",
            "title": "Run the api-gateway"
        },
        {
            "location": "/deploy/Running-the-platform/#run-the-authentication-service",
            "text": "Right click on  scava-auth-service/src/main/java/org.eclipse.scava.authservice/AuthServiceApplication.java  Then click on Run As -> Java Application",
            "title": "Run the authentication service"
        },
        {
            "location": "/deploy/Running-the-platform/#run-the-administration-dashboard",
            "text": "Scava Administration is a single page web application based on Angular 6 Framework. To get started with Angular, it's better to install Angular CLI tool to make application development more quicker and easier (Find more here: https://angular.io/guide/quickstart).  The following instructions show how to run the dashboard web app:\n  * Enter the  administration/scava-administration/  directory within the scava repository.\n  * Run the web app on port 4200 using angular-cli:  ng serve \n  * Navigate to  http://localhost:4200/",
            "title": "Run the administration dashboard"
        },
        {
            "location": "/deploy/",
            "text": "Deploying Scava\n\n\nThis repository contains information about the deployment of Scava.\n\n\n\n\nDocker-Ossmeter\n\n\nRunning the platform",
            "title": "Home"
        },
        {
            "location": "/deploy/#deploying-scava",
            "text": "This repository contains information about the deployment of Scava.   Docker-Ossmeter  Running the platform",
            "title": "Deploying Scava"
        },
        {
            "location": "/development/CROSSMINER-Component-Naming/",
            "text": "As consequence of our status of project hosted by the eclipse foundation, we have to follow a specific naming schema for all components implemented in context of SCAVA project.\n\n\nIn this section, \"component\" means big funcional componen of the SCAVA project.\n\n\n\n\n\n\n\n\nComponent\n\n\nComponentId\n\n\n\n\n\n\n\n\n\n\nDevOps Dashboard\n\n\ndashboard\n\n\n\n\n\n\nWorkflow Execution Engine\n\n\nworkflow\n\n\n\n\n\n\nKnowledge Base\n\n\nknowledgebase\n\n\n\n\n\n\nMetric Provider\n\n\nmetricprovider\n\n\n\n\n\n\nAdministration\n\n\nadministration\n\n\n\n\n\n\n\n\nProject Naming\n\n\n\n\nFor Eclipse Plugin \n\n\n\n\norg.eclipse.scava.{componentname}\n\n\n\n\n\n\nFor Maven Project : the name of the project if the ArtifactId\n\n\n\n\nIf your component is composed of one project :\n\n\n{component-name}\n\n\n\n\nIf your component is composed of several sub projects :\n\n\n{sub-component-name}\n ```\n\n## Source Code Namsespace\nAll sources must be nemspaces by : \n\n\n\n\norg.eclipse.scava.{componentname}\n\n\n\n## Maven Ids\nFor  the Maven projects:\n\n* If your component is composed of one project : \n\n\n\n\nGroup Id : org.eclipse.scava\nArtifactId : {component-name}\n\n\n\n* If your component is composed of several sub projects : \n\n\n\n\nGroup Id : org.eclipse.scava.{component-name}\nArtifactId : {sub-component-name}\n```",
            "title": "CROSSMINER Component Naming"
        },
        {
            "location": "/development/CROSSMINER-Component-Naming/#project-naming",
            "text": "For Eclipse Plugin    org.eclipse.scava.{componentname}   For Maven Project : the name of the project if the ArtifactId   If your component is composed of one project :  {component-name}  If your component is composed of several sub projects :  {sub-component-name}\n ```\n\n## Source Code Namsespace\nAll sources must be nemspaces by :   org.eclipse.scava.{componentname}  \n## Maven Ids\nFor  the Maven projects:\n\n* If your component is composed of one project :   Group Id : org.eclipse.scava\nArtifactId : {component-name}  \n* If your component is composed of several sub projects :   Group Id : org.eclipse.scava.{component-name}\nArtifactId : {sub-component-name}\n```",
            "title": "Project Naming"
        },
        {
            "location": "/development/CROSSMINER-Licensing/",
            "text": "Content\n\n\nThe CROSSMINER project is licensed under \nEclipse Public License - v 2.0\n license.\n\n\nAs consequence of our status of project hosted by the eclipse foundation, all CORSSMINER components  must contained licensing information from the first commit. In order to be compliant with the Eclipse foundation requirements, an \"Eclipse Public License - v 2.0\" license file must be added on root folder of the component project and all sources files of the project must have a license Header.\n\n\n\"Eclipse Public License\" licensing file\n\n\nThe text below must be integrated to the root folder of your project on a text file name \"LICENSE\".\n\n\nEclipse Public License - v 2.0\n\n    THE ACCOMPANYING PROGRAM IS PROVIDED UNDER THE TERMS OF THIS ECLIPSE\n    PUBLIC LICENSE (\"AGREEMENT\"). ANY USE, REPRODUCTION OR DISTRIBUTION\n    OF THE PROGRAM CONSTITUTES RECIPIENT'S ACCEPTANCE OF THIS AGREEMENT.\n\n1. DEFINITIONS\n\n\"Contribution\" means:\n\n  a) in the case of the initial Contributor, the initial content\n     Distributed under this Agreement, and\n\n  b) in the case of each subsequent Contributor:\n     i) changes to the Program, and\n     ii) additions to the Program;\n  where such changes and/or additions to the Program originate from\n  and are Distributed by that particular Contributor. A Contribution\n  \"originates\" from a Contributor if it was added to the Program by\n  such Contributor itself or anyone acting on such Contributor's behalf.\n  Contributions do not include changes or additions to the Program that\n  are not Modified Works.\n\n\"Contributor\" means any person or entity that Distributes the Program.\n\n\"Licensed Patents\" mean patent claims licensable by a Contributor which\nare necessarily infringed by the use or sale of its Contribution alone\nor when combined with the Program.\n\n\"Program\" means the Contributions Distributed in accordance with this\nAgreement.\n\n\"Recipient\" means anyone who receives the Program under this Agreement\nor any Secondary License (as applicable), including Contributors.\n\n\"Derivative Works\" shall mean any work, whether in Source Code or other\nform, that is based on (or derived from) the Program and for which the\neditorial revisions, annotations, elaborations, or other modifications\nrepresent, as a whole, an original work of authorship.\n\n\"Modified Works\" shall mean any work in Source Code or other form that\nresults from an addition to, deletion from, or modification of the\ncontents of the Program, including, for purposes of clarity any new file\nin Source Code form that contains any contents of the Program. Modified\nWorks shall not include works that contain only declarations,\ninterfaces, types, classes, structures, or files of the Program solely\nin each case in order to link to, bind by name, or subclass the Program\nor Modified Works thereof.\n\n\"Distribute\" means the acts of a) distributing or b) making available\nin any manner that enables the transfer of a copy.\n\n\"Source Code\" means the form of a Program preferred for making\nmodifications, including but not limited to software source code,\ndocumentation source, and configuration files.\n\n\"Secondary License\" means either the GNU General Public License,\nVersion 2.0, or any later versions of that license, including any\nexceptions or additional permissions as identified by the initial\nContributor.\n\n2. GRANT OF RIGHTS\n\n  a) Subject to the terms of this Agreement, each Contributor hereby\n  grants Recipient a non-exclusive, worldwide, royalty-free copyright\n  license to reproduce, prepare Derivative Works of, publicly display,\n  publicly perform, Distribute and sublicense the Contribution of such\n  Contributor, if any, and such Derivative Works.\n\n  b) Subject to the terms of this Agreement, each Contributor hereby\n  grants Recipient a non-exclusive, worldwide, royalty-free patent\n  license under Licensed Patents to make, use, sell, offer to sell,\n  import and otherwise transfer the Contribution of such Contributor,\n  if any, in Source Code or other form. This patent license shall\n  apply to the combination of the Contribution and the Program if, at\n  the time the Contribution is added by the Contributor, such addition\n  of the Contribution causes such combination to be covered by the\n  Licensed Patents. The patent license shall not apply to any other\n  combinations which include the Contribution. No hardware per se is\n  licensed hereunder.\n\n  c) Recipient understands that although each Contributor grants the\n  licenses to its Contributions set forth herein, no assurances are\n  provided by any Contributor that the Program does not infringe the\n  patent or other intellectual property rights of any other entity.\n  Each Contributor disclaims any liability to Recipient for claims\n  brought by any other entity based on infringement of intellectual\n  property rights or otherwise. As a condition to exercising the\n  rights and licenses granted hereunder, each Recipient hereby\n  assumes sole responsibility to secure any other intellectual\n  property rights needed, if any. For example, if a third party\n  patent license is required to allow Recipient to Distribute the\n  Program, it is Recipient's responsibility to acquire that license\n  before distributing the Program.\n\n  d) Each Contributor represents that to its knowledge it has\n  sufficient copyright rights in its Contribution, if any, to grant\n  the copyright license set forth in this Agreement.\n\n  e) Notwithstanding the terms of any Secondary License, no\n  Contributor makes additional grants to any Recipient (other than\n  those set forth in this Agreement) as a result of such Recipient's\n  receipt of the Program under the terms of a Secondary License\n  (if permitted under the terms of Section 3).\n\n3. REQUIREMENTS\n\n3.1 If a Contributor Distributes the Program in any form, then:\n\n  a) the Program must also be made available as Source Code, in\n  accordance with section 3.2, and the Contributor must accompany\n  the Program with a statement that the Source Code for the Program\n  is available under this Agreement, and informs Recipients how to\n  obtain it in a reasonable manner on or through a medium customarily\n  used for software exchange; and\n\n  b) the Contributor may Distribute the Program under a license\n  different than this Agreement, provided that such license:\n     i) effectively disclaims on behalf of all other Contributors all\n     warranties and conditions, express and implied, including\n     warranties or conditions of title and non-infringement, and\n     implied warranties or conditions of merchantability and fitness\n     for a particular purpose;\n\n     ii) effectively excludes on behalf of all other Contributors all\n     liability for damages, including direct, indirect, special,\n     incidental and consequential damages, such as lost profits;\n\n     iii) does not attempt to limit or alter the recipients' rights\n     in the Source Code under section 3.2; and\n\n     iv) requires any subsequent distribution of the Program by any\n     party to be under a license that satisfies the requirements\n     of this section 3.\n\n3.2 When the Program is Distributed as Source Code:\n\n  a) it must be made available under this Agreement, or if the\n  Program (i) is combined with other material in a separate file or\n  files made available under a Secondary License, and (ii) the initial\n  Contributor attached to the Source Code the notice described in\n  Exhibit A of this Agreement, then the Program may be made available\n  under the terms of such Secondary Licenses, and\n\n  b) a copy of this Agreement must be included with each copy of\n  the Program.\n\n3.3 Contributors may not remove or alter any copyright, patent,\ntrademark, attribution notices, disclaimers of warranty, or limitations\nof liability (\"notices\") contained within the Program from any copy of\nthe Program which they Distribute, provided that Contributors may add\ntheir own appropriate notices.\n\n4. COMMERCIAL DISTRIBUTION\n\nCommercial distributors of software may accept certain responsibilities\nwith respect to end users, business partners and the like. While this\nlicense is intended to facilitate the commercial use of the Program,\nthe Contributor who includes the Program in a commercial product\noffering should do so in a manner which does not create potential\nliability for other Contributors. Therefore, if a Contributor includes\nthe Program in a commercial product offering, such Contributor\n(\"Commercial Contributor\") hereby agrees to defend and indemnify every\nother Contributor (\"Indemnified Contributor\") against any losses,\ndamages and costs (collectively \"Losses\") arising from claims, lawsuits\nand other legal actions brought by a third party against the Indemnified\nContributor to the extent caused by the acts or omissions of such\nCommercial Contributor in connection with its distribution of the Program\nin a commercial product offering. The obligations in this section do not\napply to any claims or Losses relating to any actual or alleged\nintellectual property infringement. In order to qualify, an Indemnified\nContributor must: a) promptly notify the Commercial Contributor in\nwriting of such claim, and b) allow the Commercial Contributor to control,\nand cooperate with the Commercial Contributor in, the defense and any\nrelated settlement negotiations. The Indemnified Contributor may\nparticipate in any such claim at its own expense.\n\nFor example, a Contributor might include the Program in a commercial\nproduct offering, Product X. That Contributor is then a Commercial\nContributor. If that Commercial Contributor then makes performance\nclaims, or offers warranties related to Product X, those performance\nclaims and warranties are such Commercial Contributor's responsibility\nalone. Under this section, the Commercial Contributor would have to\ndefend claims against the other Contributors related to those performance\nclaims and warranties, and if a court requires any other Contributor to\npay any damages as a result, the Commercial Contributor must pay\nthose damages.\n\n5. NO WARRANTY\n\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, AND TO THE EXTENT\nPERMITTED BY APPLICABLE LAW, THE PROGRAM IS PROVIDED ON AN \"AS IS\"\nBASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR\nIMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF\nTITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR\nPURPOSE. Each Recipient is solely responsible for determining the\nappropriateness of using and distributing the Program and assumes all\nrisks associated with its exercise of rights under this Agreement,\nincluding but not limited to the risks and costs of program errors,\ncompliance with applicable laws, damage to or loss of data, programs\nor equipment, and unavailability or interruption of operations.\n\n6. DISCLAIMER OF LIABILITY\n\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, AND TO THE EXTENT\nPERMITTED BY APPLICABLE LAW, NEITHER RECIPIENT NOR ANY CONTRIBUTORS\nSHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\nEXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING WITHOUT LIMITATION LOST\nPROFITS), HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION OF THE PROGRAM OR THE\nEXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n7. GENERAL\n\nIf any provision of this Agreement is invalid or unenforceable under\napplicable law, it shall not affect the validity or enforceability of\nthe remainder of the terms of this Agreement, and without further\naction by the parties hereto, such provision shall be reformed to the\nminimum extent necessary to make such provision valid and enforceable.\n\nIf Recipient institutes patent litigation against any entity\n(including a cross-claim or counterclaim in a lawsuit) alleging that the\nProgram itself (excluding combinations of the Program with other software\nor hardware) infringes such Recipient's patent(s), then such Recipient's\nrights granted under Section 2(b) shall terminate as of the date such\nlitigation is filed.\n\nAll Recipient's rights under this Agreement shall terminate if it\nfails to comply with any of the material terms or conditions of this\nAgreement and does not cure such failure in a reasonable period of\ntime after becoming aware of such noncompliance. If all Recipient's\nrights under this Agreement terminate, Recipient agrees to cease use\nand distribution of the Program as soon as reasonably practicable.\nHowever, Recipient's obligations under this Agreement and any licenses\ngranted by Recipient relating to the Program shall continue and survive.\n\nEveryone is permitted to copy and distribute copies of this Agreement,\nbut in order to avoid inconsistency the Agreement is copyrighted and\nmay only be modified in the following manner. The Agreement Steward\nreserves the right to publish new versions (including revisions) of\nthis Agreement from time to time. No one other than the Agreement\nSteward has the right to modify this Agreement. The Eclipse Foundation\nis the initial Agreement Steward. The Eclipse Foundation may assign the\nresponsibility to serve as the Agreement Steward to a suitable separate\nentity. Each new version of the Agreement will be given a distinguishing\nversion number. The Program (including Contributions) may always be\nDistributed subject to the version of the Agreement under which it was\nreceived. In addition, after a new version of the Agreement is published,\nContributor may elect to Distribute the Program (including its\nContributions) under the new version.\n\nExcept as expressly stated in Sections 2(a) and 2(b) above, Recipient\nreceives no rights or licenses to the intellectual property of any\nContributor under this Agreement, whether expressly, by implication,\nestoppel or otherwise. All rights in the Program not expressly granted\nunder this Agreement are reserved. Nothing in this Agreement is intended\nto be enforceable by any entity that is not a Contributor or Recipient.\nNo third-party beneficiary rights are created under this Agreement.\n\nExhibit A - Form of Secondary Licenses Notice\n\n\"This Source Code may also be made available under the following\nSecondary Licenses when the conditions for such availability set forth\nin the Eclipse Public License, v. 2.0 are satisfied: {name license(s),\nversion(s), and exceptions or additional permissions here}.\"\n\n  Simply including a copy of this Agreement, including this Exhibit A\n  is not sufficient to license the Source Code under Secondary Licenses.\n\n  If it is not possible or desirable to put the notice in a particular\n  file, then You may include the notice in a location (such as a LICENSE\n  file in a relevant directory) where a recipient would be likely to\n  look for such a notice.\n\n  You may add additional accurate notices of copyright ownership.\n\n\n\n\nSource File header\n\n\nAll sources files of each CROSSMINER component projects must have a license Header. This file must be fill with the name of organization of the partner who have implemented the file ( example : Softeam,University of York ...).\n\n\nOptionally an \"And Others\" following the name of the main contributor can be added to indicate that this file is a result of a collaboration between several organization.\n\n\nExample of Java license header file\n\n\n/*******************************************************************************\n * Copyright (c) 2018 {Name of the partner} {optional: \"And Others\"}\n * This program and the accompanying materials are made\n * available under the terms of the Eclipse Public License 2.0\n * which is available at https://www.eclipse.org/legal/epl-2.0/\n *\n * SPDX-License-Identifier: EPL-2.0\n ******************************************************************************/\n\n\n\n\nComment\n\n\nAn Eclipse plugin : the Copyright Wizard plulgin could help you to manage licensing files.\n\n\nThis plug-in adds a wizard allowing to apply a copyright header comment to a selection of files in projects. The same text can be applyied on different types of files (java, xml...), the comment format being adapted in function of the content type.",
            "title": "CROSSMINER Licensing"
        },
        {
            "location": "/development/CROSSMINER-Licensing/#content",
            "text": "The CROSSMINER project is licensed under  Eclipse Public License - v 2.0  license.  As consequence of our status of project hosted by the eclipse foundation, all CORSSMINER components  must contained licensing information from the first commit. In order to be compliant with the Eclipse foundation requirements, an \"Eclipse Public License - v 2.0\" license file must be added on root folder of the component project and all sources files of the project must have a license Header.",
            "title": "Content"
        },
        {
            "location": "/development/CROSSMINER-Licensing/#eclipse-public-license-licensing-file",
            "text": "The text below must be integrated to the root folder of your project on a text file name \"LICENSE\".  Eclipse Public License - v 2.0\n\n    THE ACCOMPANYING PROGRAM IS PROVIDED UNDER THE TERMS OF THIS ECLIPSE\n    PUBLIC LICENSE (\"AGREEMENT\"). ANY USE, REPRODUCTION OR DISTRIBUTION\n    OF THE PROGRAM CONSTITUTES RECIPIENT'S ACCEPTANCE OF THIS AGREEMENT.\n\n1. DEFINITIONS\n\n\"Contribution\" means:\n\n  a) in the case of the initial Contributor, the initial content\n     Distributed under this Agreement, and\n\n  b) in the case of each subsequent Contributor:\n     i) changes to the Program, and\n     ii) additions to the Program;\n  where such changes and/or additions to the Program originate from\n  and are Distributed by that particular Contributor. A Contribution\n  \"originates\" from a Contributor if it was added to the Program by\n  such Contributor itself or anyone acting on such Contributor's behalf.\n  Contributions do not include changes or additions to the Program that\n  are not Modified Works.\n\n\"Contributor\" means any person or entity that Distributes the Program.\n\n\"Licensed Patents\" mean patent claims licensable by a Contributor which\nare necessarily infringed by the use or sale of its Contribution alone\nor when combined with the Program.\n\n\"Program\" means the Contributions Distributed in accordance with this\nAgreement.\n\n\"Recipient\" means anyone who receives the Program under this Agreement\nor any Secondary License (as applicable), including Contributors.\n\n\"Derivative Works\" shall mean any work, whether in Source Code or other\nform, that is based on (or derived from) the Program and for which the\neditorial revisions, annotations, elaborations, or other modifications\nrepresent, as a whole, an original work of authorship.\n\n\"Modified Works\" shall mean any work in Source Code or other form that\nresults from an addition to, deletion from, or modification of the\ncontents of the Program, including, for purposes of clarity any new file\nin Source Code form that contains any contents of the Program. Modified\nWorks shall not include works that contain only declarations,\ninterfaces, types, classes, structures, or files of the Program solely\nin each case in order to link to, bind by name, or subclass the Program\nor Modified Works thereof.\n\n\"Distribute\" means the acts of a) distributing or b) making available\nin any manner that enables the transfer of a copy.\n\n\"Source Code\" means the form of a Program preferred for making\nmodifications, including but not limited to software source code,\ndocumentation source, and configuration files.\n\n\"Secondary License\" means either the GNU General Public License,\nVersion 2.0, or any later versions of that license, including any\nexceptions or additional permissions as identified by the initial\nContributor.\n\n2. GRANT OF RIGHTS\n\n  a) Subject to the terms of this Agreement, each Contributor hereby\n  grants Recipient a non-exclusive, worldwide, royalty-free copyright\n  license to reproduce, prepare Derivative Works of, publicly display,\n  publicly perform, Distribute and sublicense the Contribution of such\n  Contributor, if any, and such Derivative Works.\n\n  b) Subject to the terms of this Agreement, each Contributor hereby\n  grants Recipient a non-exclusive, worldwide, royalty-free patent\n  license under Licensed Patents to make, use, sell, offer to sell,\n  import and otherwise transfer the Contribution of such Contributor,\n  if any, in Source Code or other form. This patent license shall\n  apply to the combination of the Contribution and the Program if, at\n  the time the Contribution is added by the Contributor, such addition\n  of the Contribution causes such combination to be covered by the\n  Licensed Patents. The patent license shall not apply to any other\n  combinations which include the Contribution. No hardware per se is\n  licensed hereunder.\n\n  c) Recipient understands that although each Contributor grants the\n  licenses to its Contributions set forth herein, no assurances are\n  provided by any Contributor that the Program does not infringe the\n  patent or other intellectual property rights of any other entity.\n  Each Contributor disclaims any liability to Recipient for claims\n  brought by any other entity based on infringement of intellectual\n  property rights or otherwise. As a condition to exercising the\n  rights and licenses granted hereunder, each Recipient hereby\n  assumes sole responsibility to secure any other intellectual\n  property rights needed, if any. For example, if a third party\n  patent license is required to allow Recipient to Distribute the\n  Program, it is Recipient's responsibility to acquire that license\n  before distributing the Program.\n\n  d) Each Contributor represents that to its knowledge it has\n  sufficient copyright rights in its Contribution, if any, to grant\n  the copyright license set forth in this Agreement.\n\n  e) Notwithstanding the terms of any Secondary License, no\n  Contributor makes additional grants to any Recipient (other than\n  those set forth in this Agreement) as a result of such Recipient's\n  receipt of the Program under the terms of a Secondary License\n  (if permitted under the terms of Section 3).\n\n3. REQUIREMENTS\n\n3.1 If a Contributor Distributes the Program in any form, then:\n\n  a) the Program must also be made available as Source Code, in\n  accordance with section 3.2, and the Contributor must accompany\n  the Program with a statement that the Source Code for the Program\n  is available under this Agreement, and informs Recipients how to\n  obtain it in a reasonable manner on or through a medium customarily\n  used for software exchange; and\n\n  b) the Contributor may Distribute the Program under a license\n  different than this Agreement, provided that such license:\n     i) effectively disclaims on behalf of all other Contributors all\n     warranties and conditions, express and implied, including\n     warranties or conditions of title and non-infringement, and\n     implied warranties or conditions of merchantability and fitness\n     for a particular purpose;\n\n     ii) effectively excludes on behalf of all other Contributors all\n     liability for damages, including direct, indirect, special,\n     incidental and consequential damages, such as lost profits;\n\n     iii) does not attempt to limit or alter the recipients' rights\n     in the Source Code under section 3.2; and\n\n     iv) requires any subsequent distribution of the Program by any\n     party to be under a license that satisfies the requirements\n     of this section 3.\n\n3.2 When the Program is Distributed as Source Code:\n\n  a) it must be made available under this Agreement, or if the\n  Program (i) is combined with other material in a separate file or\n  files made available under a Secondary License, and (ii) the initial\n  Contributor attached to the Source Code the notice described in\n  Exhibit A of this Agreement, then the Program may be made available\n  under the terms of such Secondary Licenses, and\n\n  b) a copy of this Agreement must be included with each copy of\n  the Program.\n\n3.3 Contributors may not remove or alter any copyright, patent,\ntrademark, attribution notices, disclaimers of warranty, or limitations\nof liability (\"notices\") contained within the Program from any copy of\nthe Program which they Distribute, provided that Contributors may add\ntheir own appropriate notices.\n\n4. COMMERCIAL DISTRIBUTION\n\nCommercial distributors of software may accept certain responsibilities\nwith respect to end users, business partners and the like. While this\nlicense is intended to facilitate the commercial use of the Program,\nthe Contributor who includes the Program in a commercial product\noffering should do so in a manner which does not create potential\nliability for other Contributors. Therefore, if a Contributor includes\nthe Program in a commercial product offering, such Contributor\n(\"Commercial Contributor\") hereby agrees to defend and indemnify every\nother Contributor (\"Indemnified Contributor\") against any losses,\ndamages and costs (collectively \"Losses\") arising from claims, lawsuits\nand other legal actions brought by a third party against the Indemnified\nContributor to the extent caused by the acts or omissions of such\nCommercial Contributor in connection with its distribution of the Program\nin a commercial product offering. The obligations in this section do not\napply to any claims or Losses relating to any actual or alleged\nintellectual property infringement. In order to qualify, an Indemnified\nContributor must: a) promptly notify the Commercial Contributor in\nwriting of such claim, and b) allow the Commercial Contributor to control,\nand cooperate with the Commercial Contributor in, the defense and any\nrelated settlement negotiations. The Indemnified Contributor may\nparticipate in any such claim at its own expense.\n\nFor example, a Contributor might include the Program in a commercial\nproduct offering, Product X. That Contributor is then a Commercial\nContributor. If that Commercial Contributor then makes performance\nclaims, or offers warranties related to Product X, those performance\nclaims and warranties are such Commercial Contributor's responsibility\nalone. Under this section, the Commercial Contributor would have to\ndefend claims against the other Contributors related to those performance\nclaims and warranties, and if a court requires any other Contributor to\npay any damages as a result, the Commercial Contributor must pay\nthose damages.\n\n5. NO WARRANTY\n\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, AND TO THE EXTENT\nPERMITTED BY APPLICABLE LAW, THE PROGRAM IS PROVIDED ON AN \"AS IS\"\nBASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR\nIMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF\nTITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR\nPURPOSE. Each Recipient is solely responsible for determining the\nappropriateness of using and distributing the Program and assumes all\nrisks associated with its exercise of rights under this Agreement,\nincluding but not limited to the risks and costs of program errors,\ncompliance with applicable laws, damage to or loss of data, programs\nor equipment, and unavailability or interruption of operations.\n\n6. DISCLAIMER OF LIABILITY\n\nEXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, AND TO THE EXTENT\nPERMITTED BY APPLICABLE LAW, NEITHER RECIPIENT NOR ANY CONTRIBUTORS\nSHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\nEXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING WITHOUT LIMITATION LOST\nPROFITS), HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\nARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION OF THE PROGRAM OR THE\nEXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF ADVISED OF THE\nPOSSIBILITY OF SUCH DAMAGES.\n\n7. GENERAL\n\nIf any provision of this Agreement is invalid or unenforceable under\napplicable law, it shall not affect the validity or enforceability of\nthe remainder of the terms of this Agreement, and without further\naction by the parties hereto, such provision shall be reformed to the\nminimum extent necessary to make such provision valid and enforceable.\n\nIf Recipient institutes patent litigation against any entity\n(including a cross-claim or counterclaim in a lawsuit) alleging that the\nProgram itself (excluding combinations of the Program with other software\nor hardware) infringes such Recipient's patent(s), then such Recipient's\nrights granted under Section 2(b) shall terminate as of the date such\nlitigation is filed.\n\nAll Recipient's rights under this Agreement shall terminate if it\nfails to comply with any of the material terms or conditions of this\nAgreement and does not cure such failure in a reasonable period of\ntime after becoming aware of such noncompliance. If all Recipient's\nrights under this Agreement terminate, Recipient agrees to cease use\nand distribution of the Program as soon as reasonably practicable.\nHowever, Recipient's obligations under this Agreement and any licenses\ngranted by Recipient relating to the Program shall continue and survive.\n\nEveryone is permitted to copy and distribute copies of this Agreement,\nbut in order to avoid inconsistency the Agreement is copyrighted and\nmay only be modified in the following manner. The Agreement Steward\nreserves the right to publish new versions (including revisions) of\nthis Agreement from time to time. No one other than the Agreement\nSteward has the right to modify this Agreement. The Eclipse Foundation\nis the initial Agreement Steward. The Eclipse Foundation may assign the\nresponsibility to serve as the Agreement Steward to a suitable separate\nentity. Each new version of the Agreement will be given a distinguishing\nversion number. The Program (including Contributions) may always be\nDistributed subject to the version of the Agreement under which it was\nreceived. In addition, after a new version of the Agreement is published,\nContributor may elect to Distribute the Program (including its\nContributions) under the new version.\n\nExcept as expressly stated in Sections 2(a) and 2(b) above, Recipient\nreceives no rights or licenses to the intellectual property of any\nContributor under this Agreement, whether expressly, by implication,\nestoppel or otherwise. All rights in the Program not expressly granted\nunder this Agreement are reserved. Nothing in this Agreement is intended\nto be enforceable by any entity that is not a Contributor or Recipient.\nNo third-party beneficiary rights are created under this Agreement.\n\nExhibit A - Form of Secondary Licenses Notice\n\n\"This Source Code may also be made available under the following\nSecondary Licenses when the conditions for such availability set forth\nin the Eclipse Public License, v. 2.0 are satisfied: {name license(s),\nversion(s), and exceptions or additional permissions here}.\"\n\n  Simply including a copy of this Agreement, including this Exhibit A\n  is not sufficient to license the Source Code under Secondary Licenses.\n\n  If it is not possible or desirable to put the notice in a particular\n  file, then You may include the notice in a location (such as a LICENSE\n  file in a relevant directory) where a recipient would be likely to\n  look for such a notice.\n\n  You may add additional accurate notices of copyright ownership.",
            "title": "\"Eclipse Public License\" licensing file"
        },
        {
            "location": "/development/CROSSMINER-Licensing/#source-file-header",
            "text": "All sources files of each CROSSMINER component projects must have a license Header. This file must be fill with the name of organization of the partner who have implemented the file ( example : Softeam,University of York ...).  Optionally an \"And Others\" following the name of the main contributor can be added to indicate that this file is a result of a collaboration between several organization.  Example of Java license header file  /*******************************************************************************\n * Copyright (c) 2018 {Name of the partner} {optional: \"And Others\"}\n * This program and the accompanying materials are made\n * available under the terms of the Eclipse Public License 2.0\n * which is available at https://www.eclipse.org/legal/epl-2.0/\n *\n * SPDX-License-Identifier: EPL-2.0\n ******************************************************************************/",
            "title": "Source File header"
        },
        {
            "location": "/development/CROSSMINER-Licensing/#comment",
            "text": "An Eclipse plugin : the Copyright Wizard plulgin could help you to manage licensing files.  This plug-in adds a wizard allowing to apply a copyright header comment to a selection of files in projects. The same text can be applyied on different types of files (java, xml...), the comment format being adapted in function of the content type.",
            "title": "Comment"
        },
        {
            "location": "/development/CROSSMINER-Repository-Organisation/",
            "text": "The SCAVA code repository  is organized by functional components with one package for each of this components. \n\n\nGeneral organisation\n\n\n\n\nmetric-platform \n\n\nplatform : Core projects of the metric platform\n\n\nplatform-extensions : Extensions of the metric platform\n\n\nmetric-providers : Metric Providers implementations projects\n\n\nfactoids : Factoids implementations projects\n\n\ntests : Test projects related to the metric-platform\n\n\nweb-dashboards : DevOps Dashboard and DevOpsDashboard components \n\n\nknowledge-base : Knowledge Base implementation\n\n\nWorkflow Execution Engine : Workflow Execution Engine implementation\n\n\neclipse-based-ide : SCAVA Eclipse plugin\n\n\napi-gateway :  API Gateway implementation.\n\n\nadministration : Administration component implementation\n\n\nmingration : Temporary directory which contains sources which are currently required to run the platform but that will be replaced during the project. \n\n\n\n\nComments",
            "title": "CROSSMINER Repository Organisation"
        },
        {
            "location": "/development/CROSSMINER-Repository-Organisation/#general-organisation",
            "text": "metric-platform   platform : Core projects of the metric platform  platform-extensions : Extensions of the metric platform  metric-providers : Metric Providers implementations projects  factoids : Factoids implementations projects  tests : Test projects related to the metric-platform  web-dashboards : DevOps Dashboard and DevOpsDashboard components   knowledge-base : Knowledge Base implementation  Workflow Execution Engine : Workflow Execution Engine implementation  eclipse-based-ide : SCAVA Eclipse plugin  api-gateway :  API Gateway implementation.  administration : Administration component implementation  mingration : Temporary directory which contains sources which are currently required to run the platform but that will be replaced during the project.",
            "title": "General organisation"
        },
        {
            "location": "/development/CROSSMINER-Repository-Organisation/#comments",
            "text": "",
            "title": "Comments"
        },
        {
            "location": "/development/Developement-Guidelignes/",
            "text": "INTEGRATION GUIDELIGNES\n\n\n\n\n[[SCAVA Repository Organisation |CROSSMINER Repository Organisation ]]\n\n\nGuideline describing how the SCAVA code repository is organised and how to add a new component in this repository\n\n\n\n\n\n\n\n[[How to name SCAVA components ? |CROSSMINER Component Naming]]\n\n\nGuideline describing naming constraints for a new scava component (component name  / java namespace / maven artefact id and group id...)\n\n\n\n\n\n\n\n[[How to name SCAVA REST services ? |Naming CORSSMINER REST Services]]\n\n\nThis guideline provide naming rules for each REST services routes implemented by the SCAVA platform.\n\n\n\n\n\n\n\n[[How to manage  Licensing ? |CROSSMINER Licensing]]\n\n\nGuideline describing licensing requirements for SCAVA components.\n\n\n\n\n\nTECHNICAL GUIDELIGNES\n\n\nREST API\n\n\nEach implemented REST services must be documented : [[REST API DOCUMENTATION |REST API Documentation]]\n \n\n\n\n\n[[How to configure the SCAVA Gateway in order to integrate a new  REST service ? |API Gateway Configuration]]\n\n\nCustomers access SCAVA services through the SCAVA API Gateway. This guideline present how to configure the API Gateway to integrate new  remote service provider. \n\n\n\n\n\n\n\n[[How to consume a SCAVA REST services ? | Consuming REST Services]]\n\n\nThis guideline is dedicated to clients which would like to used SCAVA REST Services.It adress authentication issues\n\n\n\n\n\n\n\n[[How to implement Restlet services ? |Implementing Restlet Service]]\n\n\n Guideline which describe how to integrate and implement a REST service in SCAVA platform using the RESTLET framework.\n\n\n\n\n\nDATA ACCESS\n\n\n\n\n[[How to access MongoDB database using PONGO ? |Access to MongoDB database using PONGO]]\n\n\nGuideline which describe how to the access to MongoDB database using the  PONGO framework. \n\n\n\n\n\n\n\n\n[[How to extend the SCAVA data model ? |Extend MongoDB Data Model ]]\n\n\nGuideline  which describe ways to extend the SCAVA Data Model, stored in a MongoDb database and based on the PONGO framework\n\n\n\n\n\nOSGI\n\n\n\n\n[[How to integrate OSGI service plugin in SCAVA Architecture? | OSGI Component Integration]]\n\n\nTodo\n\n\n\n\n\n\n\n[[How to communicate between OSGI plugin using JMS ? |OSGI Plugin Communication]]\n\n\nTodo\n\n\n\n\n\nTEMPLATE\n\n\n\n\n[[Guideline Template|Guideline Main Heading]]",
            "title": "Developement Guidelignes"
        },
        {
            "location": "/development/Developement-Guidelignes/#integration-guidelignes",
            "text": "[[SCAVA Repository Organisation |CROSSMINER Repository Organisation ]]  Guideline describing how the SCAVA code repository is organised and how to add a new component in this repository    [[How to name SCAVA components ? |CROSSMINER Component Naming]]  Guideline describing naming constraints for a new scava component (component name  / java namespace / maven artefact id and group id...)    [[How to name SCAVA REST services ? |Naming CORSSMINER REST Services]]  This guideline provide naming rules for each REST services routes implemented by the SCAVA platform.    [[How to manage  Licensing ? |CROSSMINER Licensing]]  Guideline describing licensing requirements for SCAVA components.",
            "title": "INTEGRATION GUIDELIGNES"
        },
        {
            "location": "/development/Developement-Guidelignes/#technical-guidelignes",
            "text": "",
            "title": "TECHNICAL GUIDELIGNES"
        },
        {
            "location": "/development/Developement-Guidelignes/#rest-api",
            "text": "Each implemented REST services must be documented : [[REST API DOCUMENTATION |REST API Documentation]]     [[How to configure the SCAVA Gateway in order to integrate a new  REST service ? |API Gateway Configuration]]  Customers access SCAVA services through the SCAVA API Gateway. This guideline present how to configure the API Gateway to integrate new  remote service provider.     [[How to consume a SCAVA REST services ? | Consuming REST Services]]  This guideline is dedicated to clients which would like to used SCAVA REST Services.It adress authentication issues    [[How to implement Restlet services ? |Implementing Restlet Service]]   Guideline which describe how to integrate and implement a REST service in SCAVA platform using the RESTLET framework.",
            "title": "REST API"
        },
        {
            "location": "/development/Developement-Guidelignes/#data-access",
            "text": "[[How to access MongoDB database using PONGO ? |Access to MongoDB database using PONGO]]  Guideline which describe how to the access to MongoDB database using the  PONGO framework.     [[How to extend the SCAVA data model ? |Extend MongoDB Data Model ]]  Guideline  which describe ways to extend the SCAVA Data Model, stored in a MongoDb database and based on the PONGO framework",
            "title": "DATA ACCESS"
        },
        {
            "location": "/development/Developement-Guidelignes/#osgi",
            "text": "[[How to integrate OSGI service plugin in SCAVA Architecture? | OSGI Component Integration]]  Todo    [[How to communicate between OSGI plugin using JMS ? |OSGI Plugin Communication]]  Todo",
            "title": "OSGI"
        },
        {
            "location": "/development/Developement-Guidelignes/#template",
            "text": "[[Guideline Template|Guideline Main Heading]]",
            "title": "TEMPLATE"
        },
        {
            "location": "/development/Implementing-Restlet-Service/",
            "text": "Implementing RESTLET services\n\n\nWhen to use this guideline ?\n\n\nThis guideline present how to create a new REST service using the RESTLET framework in the CROSSMINER platform.\n\n\nContext\n\n\nCROSSMINER project manages REST services with the RESTLET framework.\n\n\nThe usage of Restlet framework  has been inherited from the OSSMETER platform. The RESTLET framework is integrated in the platform in a single OSGI plugin :\n* org.eclipse.crossmeter.platform.client.api.  \n\n\nThe RESTLET framework used an embedded web server. In order to avoid to multiply the number of deployed web servers  , we plan to centralize all REST service implementation in the same plug-in.\n\n\nYou want to access to create a new REST Service ?\n\n\n1. Create a new Route\n\n\nTo  register a new RESTLET service, the first step is to define the route (base url which allow to access to this service) and make the link between this route an the implementation of the service.\n\n\nNaming the Route\n\n\nThe routes (Base URL) of services provided by the platform is normalize. Please refer to this guideline to know ho to define the route of the new service : \nNaming-CROSSMINER-REST-Services.html\n\n\nRegister the Route\n\n\nThe \norg.crossminer.platform.services\n plug-in contained the class \nPlatformRoute.java\n  responsible for declaring routes.\n\n\npackage org.crossminer.platform.services;\nimport org.restlet.Application;\nimport org.restlet.Restlet;\nimport org.restlet.routing.Router;\n\npublic class PlatformRoute extends Application {\n    @Override\n    public Restlet createInboundRoot() {\n        Router router = new Router(getContext());\n\n        router.attach(\"/\", PingResource.class);     \n        router.attach(\"/search\", SearchProjectResource.class);\n                ...\n                router.attach(\"/projects/p/{projectid}\", ProjectResource.class);\n        router.attach(\"/raw/metrics\", RawMetricListResource.class);\n        ...\n        return router;\n    }\n}\n\n\n\n\nRoute Example :\n\n\nrouter.attach(\"/raw/metrics\", RawMetricListResource.class);\n\n\n\n\n\n\n\"/raw/metrics\"\n: Represent the route URL.\n\n\n\"RawMetricListResource.class\"\n : Represent the class where the service to be implemented for this path.\n\n\n\n\nA route can contained some parameters. In this case, parameters are identified by a name with curly brackets \n{}\n.\n\n\n2. Implement the Service\n\n\nA service implementation is a Java class which extend the \nServerResource\n class provided by the RESTLET framework.\nTo create a new service create a new Class :\n\n Named \"\nServiceName\n\" + Resource.  Ex : ProjectCreationResource.java\n\n On a namespace based on the  route. Ex : org.crossminer.platform.services.administration for platform administration services.\n* Who extend the org.restlet.resource.ServerResource class.\n\n\nGET Service\n\n\nTo implement a service of type GET, create a new method :\n\n Based on the following signature : public final Representation represent()\n\n Add the @Get(\"json\") annotation\n\n\n\n@Get(\"json\")\npublic final Representation represent() {\n  // Initialise Response Header\n  Series<Header> responseHeaders = (Series<Header>) getResponse().getAttributes().get(\"org.restlet.http.headers\");\n   if (responseHeaders == null) {\n    responseHeaders = new Series(Header.class);\n     getResponse().getAttributes().put(\"org.restlet.http.headers\", responseHeaders);\n  }\n  responseHeaders.add(new Header(\"Access-Control-Allow-Origin\", \"*\"));\n  responseHeaders.add(new Header(\"Access-Control-Allow-Methods\", \"GET\"));\n\n  // Get Route parameter if required {projectid}\n  String projectId = (String) getRequest().getAttributes().get(\"projectid\");\n\n\n  try {\n    ....\n    // Provide Result\n    getResponse().setStatus(Status.SUCCESS_OK);\n    return new StringRepresentation(...);\n  } catch (IOException e) {\n    StringRepresentation rep = new StringRepresentation(\"{\\\"status\\\":\\\"error\\\", \\\"message\\\" : \\\"\"+e.getMessage()+\"\\\"}\");\n    rep.setMediaType(MediaType.APPLICATION_JSON);\n    getResponse().setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\n    return rep;\n  }\n}\n\n\n\n\n\nYou can also extend the \nAbstractApiResource\n , a service class  provided by the platform and dedicate to services who request a connection to MongoDb database instead of the \nServerResource\n. In this case you will have to implement the doRepresent() method.\n\n\npublic class RawMetricListResource extends AbstractApiResource {\n    public Representation doRepresent() {\n        ObjectNode res = mapper.createObjectNode();\n\n        ArrayNode metrics = mapper.createArrayNode();\n        res.put(\"metrics\", metrics);\n        ...\n        return Util.createJsonRepresentation(res);\n    }\n}\n\n\n\n\nPOST Service\n\n\nTo implement a service of type POST, crate a new method :\n\n Based on the following signature : public Representation \nmyServiceName\n (Representation entity)\n\n Add the @Post annotation\n\n\n@Post\npublic Representation myServiceName(Representation entity) {\n  try {\n    // Read Json Datas\n    JsonNode json = mapper.readTree(entity.getText());\n\n    ...\n\n    // Provide Result\n    getResponse().setStatus(Status.SUCCESS_CREATED);\n    return new StringRepresentation(...);\n\n  } catch (IOException e) {\n    StringRepresentation rep = new StringRepresentation(\"{\\\"status\\\":\\\"error\\\", \\\"message\\\" : \\\"\"+e.getMessage()+\"\\\"}\");\n    rep.setMediaType(MediaType.APPLICATION_JSON);\n    getResponse().setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\n   return rep;\n  }\n}\n\n\n\n\nDELETE Service\n\n\nTo do ....\n\n\n3. Document the Service\n\n\nThe REST services are the main integration points between platform components or between the platform and external clients. This services are the implementation of a contract between the service provider and his consumers. In order to  allow an easy integration, this contract must be documented :\n\n\n4. Test the Service\n\n\nTo do ....\n\n\nComment",
            "title": "Implementing Restlet Service"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#implementing-restlet-services",
            "text": "",
            "title": "Implementing RESTLET services"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#when-to-use-this-guideline",
            "text": "This guideline present how to create a new REST service using the RESTLET framework in the CROSSMINER platform.",
            "title": "When to use this guideline ?"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#context",
            "text": "CROSSMINER project manages REST services with the RESTLET framework.  The usage of Restlet framework  has been inherited from the OSSMETER platform. The RESTLET framework is integrated in the platform in a single OSGI plugin :\n* org.eclipse.crossmeter.platform.client.api.    The RESTLET framework used an embedded web server. In order to avoid to multiply the number of deployed web servers  , we plan to centralize all REST service implementation in the same plug-in.",
            "title": "Context"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#you-want-to-access-to-create-a-new-rest-service",
            "text": "",
            "title": "You want to access to create a new REST Service ?"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#1-create-a-new-route",
            "text": "To  register a new RESTLET service, the first step is to define the route (base url which allow to access to this service) and make the link between this route an the implementation of the service.",
            "title": "1. Create a new Route"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#naming-the-route",
            "text": "The routes (Base URL) of services provided by the platform is normalize. Please refer to this guideline to know ho to define the route of the new service :  Naming-CROSSMINER-REST-Services.html",
            "title": "Naming the Route"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#register-the-route",
            "text": "The  org.crossminer.platform.services  plug-in contained the class  PlatformRoute.java   responsible for declaring routes.  package org.crossminer.platform.services;\nimport org.restlet.Application;\nimport org.restlet.Restlet;\nimport org.restlet.routing.Router;\n\npublic class PlatformRoute extends Application {\n    @Override\n    public Restlet createInboundRoot() {\n        Router router = new Router(getContext());\n\n        router.attach(\"/\", PingResource.class);     \n        router.attach(\"/search\", SearchProjectResource.class);\n                ...\n                router.attach(\"/projects/p/{projectid}\", ProjectResource.class);\n        router.attach(\"/raw/metrics\", RawMetricListResource.class);\n        ...\n        return router;\n    }\n}  Route Example :  router.attach(\"/raw/metrics\", RawMetricListResource.class);   \"/raw/metrics\" : Represent the route URL.  \"RawMetricListResource.class\"  : Represent the class where the service to be implemented for this path.   A route can contained some parameters. In this case, parameters are identified by a name with curly brackets  {} .",
            "title": "Register the Route"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#2-implement-the-service",
            "text": "A service implementation is a Java class which extend the  ServerResource  class provided by the RESTLET framework.\nTo create a new service create a new Class :  Named \" ServiceName \" + Resource.  Ex : ProjectCreationResource.java  On a namespace based on the  route. Ex : org.crossminer.platform.services.administration for platform administration services.\n* Who extend the org.restlet.resource.ServerResource class.",
            "title": "2. Implement the Service"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#get-service",
            "text": "To implement a service of type GET, create a new method :  Based on the following signature : public final Representation represent()  Add the @Get(\"json\") annotation  \n@Get(\"json\")\npublic final Representation represent() {\n  // Initialise Response Header\n  Series<Header> responseHeaders = (Series<Header>) getResponse().getAttributes().get(\"org.restlet.http.headers\");\n   if (responseHeaders == null) {\n    responseHeaders = new Series(Header.class);\n     getResponse().getAttributes().put(\"org.restlet.http.headers\", responseHeaders);\n  }\n  responseHeaders.add(new Header(\"Access-Control-Allow-Origin\", \"*\"));\n  responseHeaders.add(new Header(\"Access-Control-Allow-Methods\", \"GET\"));\n\n  // Get Route parameter if required {projectid}\n  String projectId = (String) getRequest().getAttributes().get(\"projectid\");\n\n\n  try {\n    ....\n    // Provide Result\n    getResponse().setStatus(Status.SUCCESS_OK);\n    return new StringRepresentation(...);\n  } catch (IOException e) {\n    StringRepresentation rep = new StringRepresentation(\"{\\\"status\\\":\\\"error\\\", \\\"message\\\" : \\\"\"+e.getMessage()+\"\\\"}\");\n    rep.setMediaType(MediaType.APPLICATION_JSON);\n    getResponse().setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\n    return rep;\n  }\n}  You can also extend the  AbstractApiResource  , a service class  provided by the platform and dedicate to services who request a connection to MongoDb database instead of the  ServerResource . In this case you will have to implement the doRepresent() method.  public class RawMetricListResource extends AbstractApiResource {\n    public Representation doRepresent() {\n        ObjectNode res = mapper.createObjectNode();\n\n        ArrayNode metrics = mapper.createArrayNode();\n        res.put(\"metrics\", metrics);\n        ...\n        return Util.createJsonRepresentation(res);\n    }\n}",
            "title": "GET Service"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#post-service",
            "text": "To implement a service of type POST, crate a new method :  Based on the following signature : public Representation  myServiceName  (Representation entity)  Add the @Post annotation  @Post\npublic Representation myServiceName(Representation entity) {\n  try {\n    // Read Json Datas\n    JsonNode json = mapper.readTree(entity.getText());\n\n    ...\n\n    // Provide Result\n    getResponse().setStatus(Status.SUCCESS_CREATED);\n    return new StringRepresentation(...);\n\n  } catch (IOException e) {\n    StringRepresentation rep = new StringRepresentation(\"{\\\"status\\\":\\\"error\\\", \\\"message\\\" : \\\"\"+e.getMessage()+\"\\\"}\");\n    rep.setMediaType(MediaType.APPLICATION_JSON);\n    getResponse().setStatus(Status.CLIENT_ERROR_BAD_REQUEST);\n   return rep;\n  }\n}",
            "title": "POST Service"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#delete-service",
            "text": "To do ....",
            "title": "DELETE Service"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#3-document-the-service",
            "text": "The REST services are the main integration points between platform components or between the platform and external clients. This services are the implementation of a contract between the service provider and his consumers. In order to  allow an easy integration, this contract must be documented :",
            "title": "3. Document the Service"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#4-test-the-service",
            "text": "To do ....",
            "title": "4. Test the Service"
        },
        {
            "location": "/development/Implementing-Restlet-Service/#comment",
            "text": "",
            "title": "Comment"
        },
        {
            "location": "/development/Naming-Crossminer-REST-Services/",
            "text": "Naming Crossminer REST services\n\n\nWhen to use this guideline ?\n\n\nThis guideline present how to define the route (  a new REST service provided by the CORSSMINER platform.\n\n\nContext\n\n\nThe REST services are the main integration points between platform components or between the platform and external clients. In order to provide an unified view of  platform services , we need to used a common naming schema for all REST services provided by the platform.\n\n\nWho to name a REST service ?\n\n\n\n\n/{\ncomponentid\n}/{\ncategoryname\n}/{\nservicename\n}\n\n\n\n\n\n\n/\ncomponentid\n/\n: Name of the Architectural component which provide the service\n\n\n/\ncategoryname\n/ (Optional)\n : optional category of the service\n\n\n/\nservicename\n/\n : Name of the rest service\n\n\n\n\nComponent\n\n\n\n\n\n\n\n\nComponent\n\n\nComponentId\n\n\n\n\n\n\n\n\n\n\nDevOps Dashboard\n\n\ndashboard\n\n\n\n\n\n\nWorkflow Execution Engine\n\n\nworkflow\n\n\n\n\n\n\nKnowledge Base\n\n\nknowledgebase\n\n\n\n\n\n\nMetric Provider\n\n\nmetricprovider\n\n\n\n\n\n\nAdministration\n\n\nadministration\n\n\n\n\n\n\n\n\nComment",
            "title": "Naming Crossminer REST Services"
        },
        {
            "location": "/development/Naming-Crossminer-REST-Services/#naming-crossminer-rest-services",
            "text": "",
            "title": "Naming Crossminer REST services"
        },
        {
            "location": "/development/Naming-Crossminer-REST-Services/#when-to-use-this-guideline",
            "text": "This guideline present how to define the route (  a new REST service provided by the CORSSMINER platform.",
            "title": "When to use this guideline ?"
        },
        {
            "location": "/development/Naming-Crossminer-REST-Services/#context",
            "text": "The REST services are the main integration points between platform components or between the platform and external clients. In order to provide an unified view of  platform services , we need to used a common naming schema for all REST services provided by the platform.",
            "title": "Context"
        },
        {
            "location": "/development/Naming-Crossminer-REST-Services/#who-to-name-a-rest-service",
            "text": "/{ componentid }/{ categoryname }/{ servicename }    / componentid / : Name of the Architectural component which provide the service  / categoryname / (Optional)  : optional category of the service  / servicename /  : Name of the rest service",
            "title": "Who to name a REST service ?"
        },
        {
            "location": "/development/Naming-Crossminer-REST-Services/#component",
            "text": "Component  ComponentId      DevOps Dashboard  dashboard    Workflow Execution Engine  workflow    Knowledge Base  knowledgebase    Metric Provider  metricprovider    Administration  administration",
            "title": "Component"
        },
        {
            "location": "/development/Naming-Crossminer-REST-Services/#comment",
            "text": "",
            "title": "Comment"
        },
        {
            "location": "/development/Testing-Guidelignes/",
            "text": "Knowledge Base\n\n\nThis builds needs some configuration to run successfully. \n\n\nIn the application.properties files:\n\n \n/knowledge-base/org.eclipse.scava.knowledgebase/src/main/resources/application.properties\n\n\n \n/knowledge-base/org.eclipse.scava.knowledgebase/src/test/resources/application.properties\n\n\nEdit the following parameters:\n\n\nlucene.index.folder=/tmp/scava_lucene/\negit.github.token=3f5accc2f8f4cXXXXXXXXX73b201692fc1df57\n\n\n\n\nTo generate the GitHub access token you need to go to \nyour own GitHub account\n and create a new one. Once it's done simply restart the tests, they should pass.",
            "title": "Testing Guidelignes"
        },
        {
            "location": "/development/Testing-Guidelignes/#knowledge-base",
            "text": "This builds needs some configuration to run successfully.   In the application.properties files:   /knowledge-base/org.eclipse.scava.knowledgebase/src/main/resources/application.properties    /knowledge-base/org.eclipse.scava.knowledgebase/src/test/resources/application.properties  Edit the following parameters:  lucene.index.folder=/tmp/scava_lucene/\negit.github.token=3f5accc2f8f4cXXXXXXXXX73b201692fc1df57  To generate the GitHub access token you need to go to  your own GitHub account  and create a new one. Once it's done simply restart the tests, they should pass.",
            "title": "Knowledge Base"
        },
        {
            "location": "/using/Consuming-REST-Services/",
            "text": "Consuming REST services\n\n\nWhen to use ?\n\n\nThis guideline describes general way of consuming REST services of CROSSMINER. Its basically for the use of CROSSMINER rest APIs in other tools/applications.\n\n\nREST API Reference\n\n\nThe reference guide presenting all REST services implemented by CROSSMINER is available [[right here |Developement Guidelignes]].\n\n\nAPI Gateway\n\n\nThe CROSSMINER integrated platform provide a centralized access point to all web services implemented by the different tools involved in the platform : the CROSSMINER API Gateway.\n\n\nAll web service request form clients have to go through the gateway.\n\n\n\n\nThe api gateway is in charge to redirect the client request to the right service provider. The gateway also manage authentication mechanism for all services provided by the integrated platform.\n\n\nPlatform Authentication\n\n\nThe CROSSMIER API Gateway is secruized using JSON Web Tokens (JWT https://jwt.io).\n1. To obtain an access to a specific service, the client must authenticate with the authentication service.If the authentication success,he recived a web token that should be include in the header of all of his future requests.\n1. When the client request a specific service, the api gateway valivate the token from the authentication  service. If the token is valide, the api gateway transmite the request to the related service.\n\n\nAuthentication in Java\n\n\nRetrieve a Web Tokens from authentication service\n\n\nprivate String getAuthToken(String login,String password) throws MalformedURLException, IOException, ProtocolException {\n  // Authentication Service URI\n  URL url = new URL(\"http://localhost:8086/api/authentication\");\n\n  // AUthentication Request\n  HttpURLConnection connection = (HttpURLConnection) url.openConnection();\n  connection.setDoOutput(true);\n  connection.setRequestMethod(\"POST\");\n  connection.setRequestProperty(\"Content-Type\", \"application/json\");\n\n  String input = \"{\\\"username\\\":\\\"\"+login+\"\\\",\\\"password\\\":\\\"\"+password+\"\\\"}\";\n  OutputStream os = connection.getOutputStream();\n  os.write(input.getBytes());\n  os.flush();\n\n  if (connection.getResponseCode() != HttpURLConnection.HTTP_OK) {\n    throw new RuntimeException(\"Failed : HTTP error code : \"+ connection.getResponseCode());\n  }\n\n  connection.disconnect();\n\n  // A JWT Token is return in the Header of the response\n  return connection.getHeaderField(\"Authorization\");\n}\n\n\n\n\nREST Service Call\n\n\ncurl -d '{\"username\":\"admin\", \"password\":\"admin\"}' -H \"Content-Type: application/json\" -X POST http://localhost:8086/api/authentication\n\n\n\n\nService Consumption\n\n\nTo consume a REST service provided by the integrated platform, the client must include the Token in the header of his request.\n\n\n```java\n// Service URL\nURL url = new URL(\"http://localhost:8086/api/users\");\nHttpURLConnection connection = (HttpURLConnection) url.openConnection();\nconnection.setRequestMethod(\"GET\");\n\n\n// Add Token to the request header\nconnection.setRequestProperty(\"Authorization\",token);\n```\n\n\nComment",
            "title": "Consuming REST Services"
        },
        {
            "location": "/using/Consuming-REST-Services/#consuming-rest-services",
            "text": "",
            "title": "Consuming REST services"
        },
        {
            "location": "/using/Consuming-REST-Services/#when-to-use",
            "text": "This guideline describes general way of consuming REST services of CROSSMINER. Its basically for the use of CROSSMINER rest APIs in other tools/applications.",
            "title": "When to use ?"
        },
        {
            "location": "/using/Consuming-REST-Services/#rest-api-reference",
            "text": "The reference guide presenting all REST services implemented by CROSSMINER is available [[right here |Developement Guidelignes]].",
            "title": "REST API Reference"
        },
        {
            "location": "/using/Consuming-REST-Services/#api-gateway",
            "text": "The CROSSMINER integrated platform provide a centralized access point to all web services implemented by the different tools involved in the platform : the CROSSMINER API Gateway.  All web service request form clients have to go through the gateway.   The api gateway is in charge to redirect the client request to the right service provider. The gateway also manage authentication mechanism for all services provided by the integrated platform.",
            "title": "API Gateway"
        },
        {
            "location": "/using/Consuming-REST-Services/#platform-authentication",
            "text": "The CROSSMIER API Gateway is secruized using JSON Web Tokens (JWT https://jwt.io).\n1. To obtain an access to a specific service, the client must authenticate with the authentication service.If the authentication success,he recived a web token that should be include in the header of all of his future requests.\n1. When the client request a specific service, the api gateway valivate the token from the authentication  service. If the token is valide, the api gateway transmite the request to the related service.  Authentication in Java  Retrieve a Web Tokens from authentication service  private String getAuthToken(String login,String password) throws MalformedURLException, IOException, ProtocolException {\n  // Authentication Service URI\n  URL url = new URL(\"http://localhost:8086/api/authentication\");\n\n  // AUthentication Request\n  HttpURLConnection connection = (HttpURLConnection) url.openConnection();\n  connection.setDoOutput(true);\n  connection.setRequestMethod(\"POST\");\n  connection.setRequestProperty(\"Content-Type\", \"application/json\");\n\n  String input = \"{\\\"username\\\":\\\"\"+login+\"\\\",\\\"password\\\":\\\"\"+password+\"\\\"}\";\n  OutputStream os = connection.getOutputStream();\n  os.write(input.getBytes());\n  os.flush();\n\n  if (connection.getResponseCode() != HttpURLConnection.HTTP_OK) {\n    throw new RuntimeException(\"Failed : HTTP error code : \"+ connection.getResponseCode());\n  }\n\n  connection.disconnect();\n\n  // A JWT Token is return in the Header of the response\n  return connection.getHeaderField(\"Authorization\");\n}  REST Service Call  curl -d '{\"username\":\"admin\", \"password\":\"admin\"}' -H \"Content-Type: application/json\" -X POST http://localhost:8086/api/authentication",
            "title": "Platform Authentication"
        },
        {
            "location": "/using/Consuming-REST-Services/#service-consumption",
            "text": "To consume a REST service provided by the integrated platform, the client must include the Token in the header of his request.  ```java\n// Service URL\nURL url = new URL(\"http://localhost:8086/api/users\");\nHttpURLConnection connection = (HttpURLConnection) url.openConnection();\nconnection.setRequestMethod(\"GET\");  // Add Token to the request header\nconnection.setRequestProperty(\"Authorization\",token);\n```",
            "title": "Service Consumption"
        },
        {
            "location": "/using/Consuming-REST-Services/#comment",
            "text": "",
            "title": "Comment"
        }
    ]
}